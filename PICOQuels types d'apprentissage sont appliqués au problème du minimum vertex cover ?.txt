==== MÉTA ====
TITRE COURT : Apprentissages pour Minimum Vertex Cover
QUESTION DE RECHERCHE : Quels types d'apprentissage sont appliqués au problème du minimum vertex cover ?
DOMAINE / PROBLÈME : Théorie des graphes et optimisation combinatoire; problème de couverture minimale de sommets (Minimum Vertex Cover, MVC).
TYPE DE QUESTION (théorique / expérimental / mixte) : mixte
RÉSUMÉ PICO (2–3 lignes) : On étudie des approches d’apprentissage (supervisé, imitation, renforcement) appliquées à MVC, construites comme fonctions de scoring/ranking de sommets ou politiques de sélection séquentielle. On compare ces méthodes à des algorithmes classiques exacts/approximatifs sur des familles de graphes standard, en mesurant coût de solution, ratio empirique à l’optimum et temps de calcul.

==== PICO ====
PROBLÈMES / INSTANCES (P) : Graphes simples non dirigés, non pondérés en priorité; variantes pondérées en extension. Familles couvrant graphes aléatoires (Erdős–Rényi G(n,p), Barabási–Albert), réguliers, planaires si disponibles, et graphes réels (SNAP/SuiteSparse) avec tailles de 10^2 à 10^5 sommets. Séparation entraînement/validation/test sans chevauchement structurel; distribution décalée pour tester la généralisation hors-distribution.
ALGORITHME / MÉTHODE (I) : Familles d’apprentissage pour MVC:
- apprentissage supervisé (p.ex., GNN de message passing) pour scorer/ranger les sommets, avec décodage glouton ou par coupes;
- imitation learning des trajectoires d’oracles/heuristiques (apprendre à reproduire de bonnes séquences de sélection);
- apprentissage par renforcement (politique séquentielle, policy gradient/Q-learning) optimisant une récompense liée à la taille de la couverture et à la validité;
- intégration neuro-symbolique dans des solveurs (learning-to-branch/learning-to-cut) guidant un IP/CP sans changer l’optimalité du noyau exact.
COMPARATEUR (C) : Baselines non apprenantes et exactes: 2-approximation par appariement maximal, heuristiques gloutonnes (degré, coût/poids), recherche locale, kernelization standard; solveur IP exact pour obtenir l’optimum ou un bound serré sur des instances moyennes; variantes heuristiques de solveurs (sans apprentissage) à budget égal.
MESURES / PROPRIÉTÉS (O) : Taille de la couverture |S|; écart relatif à l’optimum (|S|/OPT − 1) ou ratio empirique |S|/OPT; taux de validité (couverture complète); temps CPU/GPU et mémoire; stabilité et variance inter-seeds; capacité de généralisation (dégradation hors-distribution). Côté théorique: existence éventuelle de garanties (bornes d’approximation/complexité) déclarées par les auteurs; absence de garantie si non fournie.

==== DÉLIMITATION DE LA PORTÉE ====
- Reformulations proposées (2–3) :
  1) Comparer apprentissage supervisé/imitation (GNN de scoring) vs renforcement séquentiel pour MVC non pondéré, sur graphes 10^2–10^5 sommets.
  2) Évaluer l’apport du learning-to-branch/cut pour MVC dans un solveur exact, à budget fixe, versus heuristiques internes classiques.
  3) Étudier les garanties d’approximation obtenues (si publiées) par des méthodes apprenantes pour MVC et leurs conditions de validité.
- Reformulation retenue : 1) Comparer GNN supervisé/imitation vs renforcement pour MVC non pondéré, avec décodage glouton, face à baselines exactes/approximatives.
- Inclusions / exclusions méthodologiques internes au PICO (périmètre technique uniquement) : Inclus: GNN de message passing, politiques séquentielles RL, imitation d’oracles, intégration dans solveurs. Exclus: supervision nécessitant l’optimum sur très grands graphes si irréaliste; méthodes purement heuristiques non comparables; variantes dirigées/hypergraphes (hors périmètre principal).

==== PROTOCOLE D’ÉVALUATION / BENCHMARK (SI EXPÉRIMENTAL) ====
- Données/familles: G(n,p) avec p∈{0.01,0.05,0.1}; Barabási–Albert m∈{2,4,8}; réguliers k∈{3,5}; planaires synthétiques; et un sous-ensemble de graphes réels hétérogènes. Splits: train/val/test disjoints, avec tailles test plus grandes que train pour tester l’échelle.
- Budgets: temps/instance identique; plafond d’epochs; early stopping sur validation; même matériel de calcul; limite mémoire identique.
- Seeds: ≥5 seeds; rapporter moyenne ± écart-type; fixer RNGs.
- Métriques: |S|, ratio |S|/OPT (avec OPT via IP ou bound serré), taux de validité, temps CPU/GPU, mémoire; courbes performance-temps.
- Équité: mêmes instances et budgets; même pré/post-traitement; hyperparamètres validés sans regarder le test; pas de fine-tuning sur test.

==== QUALITÉ & REPRODUCTIBILITÉ ====
- Code/disponibilité: dépôt public avec scripts d’entraînement/évaluation, checkpoints et instructions; datasets/splits publiés ou script de génération déterministe.
- Versionnement: empreinte logicielle (versions libs, CUDA), commit hash; configuration et hyperparamètres enregistrés.
- Contrôle des aléas: seeds fixées; ordre de chargement déterministe; redémarrages reproductibles; journalisation complète.
- Transparence baselines: implémentations citées; paramètres documentés; mêmes limites de temps/mémoire; vérification croisée de résultats sur petits graphes contre IP exact.

==== HYPOTHÈSES & INCERTITUDES ====
- Hypothèses posées: graphes simples non pondérés comme cas principal; disponibilité d’un solveur IP pour estimer OPT sur instances petites/moyennes; ressources GPU modérées; familles de graphes représentatives.
- Incertitudes: transférabilité hors-distribution; coût d’annotation pour supervision/IL; sensibilité au choix d’architecture GNN; impact des kernelizations; garanties théoriques rarement universelles pour méthodes apprenantes.

==== CHECKLIST FINALE ====
- P/I/C/O alignés; comparateurs et métriques définis; protocole expérimental précisé; hypothèses explicites; dernière ligne du fichier = nom de fichier.

==== NOM DE FICHIER ====
PICOQuels types d'apprentissage sont appliqués au problème du minimum vertex cover ?.txt
