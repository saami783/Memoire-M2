# Reinforcement Learning for Variational Quantum Circuits Design 

Simone Foderà<br>Politecnico di Milano<br>Milano, Italy<br>simone.fodera@mail.polimi.it Gloria Turati<br>Politecnico di Milano<br>Milano, Italy<br>gloria.turati@polimi.it

Riccardo Nembrini<br>Politecnico di Milano<br>Milano, Italy<br>riccardo.nembrini@polimi.it

Maurizio Ferrari Dacrema<br>Politecnico di Milano<br>Milano, Italy<br>maurizio.ferrari@polimi.it

## Paolo Cremonesi <br> Politecnico di Milano <br> Milano, Italy <br> paolo.cremonesi@polimi.it

Abstract-Variational Quantum Algorithms have emerged as promising tools for solving optimization problems on quantum computers. These algorithms leverage a parametric quantum circuit called ansatz, where its parameters are adjusted by a classical optimizer with the goal of optimizing a certain cost function. However, a significant challenge lies in designing effective circuits for addressing specific problems. In this study, we leverage the powerful and flexible Reinforcement Learning paradigm to train an agent capable of autonomously generating quantum circuits that can be used as ansatzes in variational algorithms to solve optimization problems. The agent is trained on diverse problem instances, including Maximum Cut, Maximum Clique and Minimum Vertex Cover, built from different graph topologies and sizes. Our analysis of the circuits generated by the agent and the corresponding solutions shows that the proposed method is able to generate effective ansatzes. While our goal is not to propose any new specific ansatz, we observe how the agent has discovered a novel family of ansatzes effective for Maximum Cut problems, which we call $R_{y z}$-connected. We study the characteristics of one of these ansatzes by comparing it against state-of-the-art quantum algorithms across instances of varying graph topologies, sizes, and problem types. Our results indicate that the $R_{y z}$-connected circuit achieves high approximation ratios for Maximum Cut problems, further validating our proposed agent. In conclusion, our study highlights the potential of Reinforcement Learning techniques in assisting researchers to design effective quantum circuits which could have applications in a wide number of tasks.

Index Terms-Quantum Computing, NISQ, Reinforcement Learning, Variational Quantum Algorithms

## I. INTRODUCTION

Quantum computing has gained attention for its potential to tackle problems that are computationally challenging for classical computers. Variational Quantum Algorithms (VQAs) [1], which employ a parametric quantum circuit and a classical optimizer to adjust the circuit parameters, represent a promising paradigm in the Noisy Intermediate-Scale Quantum (NISQ) [2] era. However, a key challenge in these algorithms lies in identifying an appropriate ansatz for the specific problem being addressed. Approaches for selecting suitable ansatzes include leveraging problem-specific properties, such as symmetries [3]-[5], or using adaptive methods that dynamically
modify circuits by adding and removing gates during execution [6]-[8]. However, identifying which problem properties can be exploited is non-trivial and adaptive methods rely on carefully designed heuristics and may require numerous circuit executions to converge to a suitable ansatz.

Reinforcement Learning (RL) is a Machine Learning paradigm where an agent learns to perform actions to achieve a desired goal. By receiving a reward for each action taken, the agent iteratively refines its strategy to maximize the cumulative reward, ultimately achieving the desired objective. The RL paradigm is highly flexible and has already been successfully deployed for many tasks in quantum computing [9]-[11], including circuit design [12], [13]. One crucial difference between the RL paradigm and the existing adaptive approaches is that it is possible with RL to learn how to build circuits without relying on manually crafted heuristics or domain-specific knowledge. Furthermore, RL can be effective in scenarios with very large solution spaces, such as the one of possible quantum circuits.

In our work we present a RL-based algorithm designed to search for variational quantum circuits for solving optimization problems. We train the agent on instances of the Maximum Cut, Maximum Clique, and Minimum Vertex Cover problems and analyze the solution quality and the properties of the circuits obtained. Our findings show that the agent is capable of building circuits leading to satisfactory results, particularly on the Maximum Cut problem.

Moreover, during training on the Maximum Cut problem, the agent discovered effective circuits with a regular structure, which we denote as $R_{y z}$-connected, characterized by circuits with only $R_{y z}$ gates connecting all the qubits. We test a specific member of this family, referred to as Linear circuit and discuss how they could be implemented on the hardware. Specifically, we test its performance against state-of-the-art quantum algorithms on diverse Quadratic Unconstrained Binary Optimization (QUBO) problems with varying underlining graph topologies and sizes. Our findings reveal that the Linear circuit is able to find high-quality solutions on the Maximum Cut problem, but it is less effective on the others.In summary, our contributions are the following:

- We propose a Reinforcement Learning agent whose purpose is to generate Variational Quantum Circuits able to solve optimization problems;
- We show that the proposed agent is able to build circuits that exhibit good approximation ratios for various optimization problems;
- We investigate a specific family of circuits that the agent has discovered, which we call $R_{y z}$-connected, and show that they generalize well and can be used to tackle other instances of the same problem.
Overall, our study shows the potential of RL-based approaches for constructing effective variational quantum circuits. Moreover, this methodology holds promise for broader applications within quantum computing, including designing more general circuits or optimizing circuit properties.


## II. Variational Quantum Algorithms

Variational Quantum Algorithms (VQAs) [1] represent a class of hybrid quantum algorithms that can be used to tackle certain optimization problems and are characterized by the presence of a parametric quantum circuit, denoted as ansatz, and a classical optimizer. The goal of the classical optimizer is to adjust the circuit parameters by minimizing a predefined cost function, in such a way that the execution of the circuit with optimized parameters yields the solution to the given optimization problem. In recent years, VQAs have known large diffusion due to their potential to tackle complex problems using near-term quantum devices. Indeed, the variational approach enables the utilization of shallower circuits, making these algorithms more resilient to noise and qubit decoherence.

One of the most widely utilized VQAs is the Variational Quantum Eigensolver (VQE) [14], [15], which allows to determine the ground state of a given Hamiltonian $H$, and is largely applied in quantum chemistry [16], [17]. Specifically, this algorithm employs a suitable ansatz capable of generating the final parametric state $|\psi(\theta)\rangle$, where $\theta$ denotes a parameter vector. The objective is to identify the circuit parameters that minimize the cost function $\langle\psi(\theta)| H|\psi(\theta)\rangle$, also denoted as $\langle H\rangle$, through a variational approach. Notice that, when using real quantum hardware, we do not have direct access to the expectation $\langle\psi(\theta)| H|\psi(\theta)\rangle$, but this quantity can be estimated by executing the circuit a number $n_{\text {shots }}$ of times and computing the quantity:

$$
\langle H\rangle^{*}=\langle\psi(\theta)| H|\psi(\theta)\rangle^{*}=\frac{1}{n_{\text {shots }}} \sum_{i=1}^{n_{\text {shots }}}\left\langle\tilde{\psi}_{i}\right| H\left|\tilde{\psi}_{i}\right\rangle
$$

where $\left|\tilde{\psi}_{i}\right\rangle$ denotes the basis state obtained after performing the measurement at the $i$-th execution of the circuit.

Another widely adopted VQA is the Quantum Approximate Optimization Algorithm (QAOA) [18], [19], often employed to address combinatorial optimization problems [20]-[26]. Similarly to VQE, QAOA aims to minimize the expectation value of a designated cost Hamiltonian on the circuit's final
state. However, QAOA employs a predefined circuit comprising an initial layer of Hadamard gates followed by $p$ layers, each implementing two parametric operators: the cost operator, which depends on the cost Hamiltonian, and the mixer operator, which allows to further explore the solution space. QAOA can be considered as a discretized form of continuous-time quantum evolution.

One variant of QAOA is the multi-angle QAOA (maQAOA) [27], which shares the same objective and circuit structure as QAOA, but uses distinct parameters for each parametric gate associated with the cost and mixer operators. Whereas ma-QAOA enhances space exploration capability using the same circuit structure and depth as QAOA, it also increases the computational load on the classical optimizer due to the higher number of parameters, rendering a careful trade-off necessary.

Another variant, QAOA+ [28], extends the ansatz used by QAOA with $p=1$ by introducing an additional problemindependent layer consisting of $R_{z z}$ gates, and a mixer layer with $R_{x}$ gates. This results in a circuit with Hadamard, cost and mixer layer, and the two newly introduced components. Notably, this structure is not repeated. Since each gate in the additional layers is independently parameterized, the QAOA+ ansatz results in a deeper circuit with $2 n-1$ additional parameters compared to QAOA with $p=1$. Similar to ma-QAOA, the higher number of parameters enables a broader exploration of the solution space, but at the same time increases the computational burden on the classical optimizer.

However, one critical challenge in the application of VQAs is the identification of suitable circuits for addressing specific problems [29]-[32]. An ideal ansatz should have a limited number of gates and depth to mitigate noise and decoherence, utilize the native gates of the hardware to simplify implementation and reduce circuit depth, as well as effectively sample the correct solution to the optimization problem. In particular, one significant obstacle to finding the correct solution to the optimization problem lies in the phenomenon of barren plateaus [33]-[39]. Barren plateaus occur when the gradient of the cost function exponentially vanishes as the system size increases, resulting in a flat landscape in which the classical optimizer struggles to escape local optima and may not be able to find good parameters for the circuit. To address this challenge, strategies for selecting suitable ansatzes have been explored. These include leveraging problem-specific properties [3]-[5], [18] and employing adaptive algorithms [6]-[8].

Adaptive Variational Quantum Algorithms are a family of methods which dynamically construct the quantum circuit by iteratively adding and removing gates throughout the algorithm execution. This approach allows to explore various gate configurations and choose the most suitable circuit structures for a given problem. One category of adaptive VQAs, proposed in the literature, includes ADAPT-VQE [40], qubit-ADAPTVQE [41], QEB-ADAPT-VQE [42], and Overlap-ADAPTVQE [43], adaptive variants of VQE. These algorithms aim to find the ground state of a Hamiltonian operator representing the energy of a molecule, and their distinguishing featurelies in the construction of the ansatz, which is achieved by adding gates selected from a pool which depends on the specific chemistry problem being addressed. Additionally, there exists an adaptive version of QAOA [44], which, at each iteration, determines the most appropriate mixer for the following layer of the circuit. Other adaptive VQAs adopt a genetic approach [45]-[47], employ more generalized Machine Learning techniques for circuit construction [48]-[50] or make use of Reinforcement Learning as described in Section III-A.

## III. REINFORCEMENT LEARNING

Our objective is to use a Machine Learning model to design new circuits capable of finding the ground state of a Hamiltonian. This problem requires exploring a large solution space of potential circuits, and is strongly influenced by the specific Hamiltonian under consideration. Consequently, creating an exhaustive dataset of quantum circuits for supervised learning is impractical. Thus, we choose to use a Reinforcement Learning (RL) approach, where an agent interacts with an environment to achieve a specific goal. This enables us to generate data, i.e. quantum circuits, and evaluate their performance during training. Because of the complexity of this topic, in this section we only describe the fundamental concepts of RL and the selected algorithm. For a comprehensive overview of this technology, the interested reader may refer to [51].

In RL, the agent interacts with the environment in discrete time steps. At each step $t$, the environment is in a particular state $s_{t}$, which is observed by the agent. Based on this observation, the agent performs an action $a_{t}$, which may have an effect on the environment, causing the transition to a new state $s_{t+1}$. The agent receives a reward $r_{t}$, a value depending on the quality of the action taken. Starting from an initial state and cyclically interacting with the environment until a termination condition is reached, the agent completes an episode. Let us consider a practical example, where the agent is a robot whose goal is to move an object from one place to another in an environment constituted by a table. In this scenario, the actions correspond to the movements that the robot's mechanical arms can perform, the state of the environment is represented by the current position of the object on the table, and the reward is a function which increases as the distance between the object and its target location decreases. An episode starts with the object in an initial position on the table and ends when the robot has successfully placed the object at the target position.

Spanning through multiple episodes, the objective of the agent is to learn which actions to perform in order to obtain the highest cumulative reward, or return. Specifically, the return at time step $t$ is the weighted sum of rewards starting from $t$ until the end of the episode:

$$
g_{t}=\sum_{k=0}^{t_{e}} \gamma^{k} r_{t+k+1}
$$

where $t_{e}$ is the number of remaining steps until the end of the episode and $\gamma \in(0,1)$ represents the discount factor.

This factor serves two purposes: facilitating convergence and balancing short-term versus long-term rewards.

When choosing a new action in each state, the agent follows a policy $\pi$, which is a probability distribution on the set of all actions, conditioned on the state:

$$
\pi(a \mid s)=P\left(a_{t}=a \mid s_{t}=s\right)
$$

Various methods exist to learn an optimal policy. In this work we use Proximal Policy Optimization (PPO), which is currently a state-of-the-art Deep Reinforcement Learning algorithm introduced by OpenAI [52]. PPO makes use of two neural networks with the same structure, respectively called policy and value network. Both networks receive an appropriate representation of the environment's state as input. The policy network then outputs a probability distribution on the possible actions at time step $t$, from which action $a_{t}$ is then sampled. On the other hand, the value network outputs a single value estimating the value function, which quantifies the quality of the state in terms of expected return when following the policy $\pi$ :

$$
V_{\pi}(s)=\mathbb{E}_{\pi}\left[g_{t} \mid s_{t}=s\right]
$$

While the policy network effectively chooses the actions to perform, the value network is used to estimate the so-called advantage function:

$$
A_{\pi}(s, a)=Q_{\pi}(s, a)-V_{\pi}(s)
$$

Here, $Q_{\pi}$ represents the state-action value function, which is the expected return obtained by starting in state $s$, taking action $a$ and then following the policy $\pi$ :

$$
Q_{\pi}(s, a)=\mathbb{E}_{\pi}\left[g_{t} \mid s_{t}=s, a_{t}=a\right]
$$

Thus, the advantage measures the potential benefit of taking action $a$ in state $s$, independently of the quality of that state. In order to learn an optimal policy, PPO performs gradient ascent with the goal of maximizing an objective function that incorporates both the advantage and a loss that helps the value network in learning how to better estimate the real value function. Moreover, a clipping mechanism is implemented to avoid a too large update to the policy during training. For further details on the loss and implementation, we refer to the original articles [52], [53].

## A. Reinforcement Learning for Quantum Computing

In recent years, RL techniques have been applied to various challenging tasks in quantum computing. Some studies focus on optimizing circuit parameters [9]-[11], while others tackle circuit learning tasks consisting in generating quantum circuits to transform an initial state into a target state [54]-[58]. This task is particularly useful because it can be applied to the crucial step of quantum circuit compiling. Additionally, RL has been used to learn optimization strategies aimed at reducing circuit depth and gate count [59]. Furthermore, RL algorithms have been applied to the task of designing quantum circuits tailored for Machine Learning [12] and optimization [13] problems. Specifically, [12] discusses the use of RL indesigning parameterized quantum circuits for classification tasks, while [13] employs RL to find suitable ansatzes for VQE to determine the ground state energy of specific molecules. It is worth noting that the approach taken by [13] tackles our same task of finding circuits to generate the ground state of a Hamiltonian. However, the RL agent is specifically tailored for chemistry problems, and the architecture may not be directly applicable to other domains. In contrast, our work introduces a novel RL algorithm designed for more general optimization problems and differs in many crucial components: architecture for the agent, state representations, rewards, and available actions.

## IV. AGENT DESIGN AND TRAINING

In this study we propose a RL-based algorithm called Reinforcement Learning for Variational Quantum Circuits (RLVQC), designed to learn how to build new quantum circuits aimed at finding the ground state of the Hamiltonian associated with a given optimization problem. In this section we describe the different components of RLVQC, including environment, actions, and reward. Then, we present the experimental setup and specify some implementation details useful to reproduce the experiments.

## A. Environment, Actions, Reward

In RLVQC, the environment is represented by a parametric circuit with $n$ qubits. At each step $t$, the agent performs an action consisting in adding a new gate to the circuit. The environment configuration at the beginning of each episode is represented by a circuit with a single layer of Hadamard gates. The action set $\mathcal{A}$ comprises the gates that the agent can insert into the circuit. Specifically, $\mathcal{A}$ is the union of the following sets:

- $\mathcal{S}=\left\{R_{a}^{i}(\theta) \mid a \in\{x, y, z\}, i=0, \ldots, n-1\right\}$
- $\mathcal{D}=\left\{R_{a b}^{i j}(\theta) \mid a, b \in\{x, y, z\}, i, j=0, \ldots, n-1, i<j\right\}$ where $R_{a}^{i}$ is a single rotation gate applied to qubit $i$ and $R_{a b}^{i j}$ is a double rotation applied to a pair of different qubits $i$ and $j$. Formally, denoting as $\sigma_{a}$ the Pauli-a matrix for all $a, b \in\{x, y, z\}$, the double rotations are defined as:

$$
R_{a b}(\theta)=e^{-i \frac{\theta}{2} \sigma_{a} \otimes \sigma_{b}}
$$

A specific double rotation $R_{a b}(\theta)$ can be decomposed in simpler gates as follows:

where $U_{a}$ and $U_{b}$ are gates which map the $a$ and $b$ axis into the $z$ axis respectively. Thus, $U_{x}=H, U_{y}=R_{x}\left(\frac{\pi}{2}\right)$, and $U_{z}=$ $I$. These double rotations are able to generate entanglement between qubits.

The gates in the set $\mathcal{A}$ are chosen because they exhibit identity-like behavior when their parameters are set to 0 . This property is advantageous because starting from a circuit with
optimized parameters and adding a new gate with parameters set to 0 allows the optimization process to begin from a favorable initial point rather than a random one. This approach potentially reduces computational time and mitigates the risk of converging to a local minimum [60].

At each time step $t$, the agent chooses a gate as an action to be applied to the environment, which is updated by adding that gate with parameter $\theta_{t}=0$ to the circuit. Notice that all the gates are independently parametrized. Subsequently, the circuit parameters are optimized using the classical optimizer COBYLA ${ }^{1}$, which has been shown to be effective in noise-free scenarios without demanding an excessive computational cost [61], [62]. COBYLA is run for a maximum of 1000 iterations with the goal of minimizing the cost function given by the expectation of the problem Hamiltonian on the final state of the circuit, defined in (1). Such expectation is estimated by simulating the circuit 1000 times $^{2}$. The choice of estimating the expectation instead of computing it exactly is made to reflect the use of an actual quantum computer. Indeed, on real quantum devices, we do not have direct access to the quantum state, but we can only estimate it by performing multiple measurements.

After COBYLA converges, the circuit using the optimized parameters is executed an additional 1000 times to obtain the estimated probability distribution of the final state of the circuit, in the form of a vector of $2^{n}$ real-valued elements. This probability distribution represents the next state observed by the agent. Notice that the design of an effective representation for the environment state is not trivial and depends on several factors related to the specific task and the agent's architecture. For this reason, designing new state representations specifically tailored for quantum systems can be considered an important and wide research area that goes beyond the scope of this paper.

The reward at time step $t$ is defined to align with our goal of minimizing the expectation value of the Hamiltonian and the circuit depth while the agent learns to maximize the return (2). Specifically, the reward is expressed as:

$$
r_{t}=-\langle H\rangle_{t}^{*}-\beta \cdot d_{t}
$$

where $\langle H\rangle_{t}^{*}$ is an estimate of the current expectation value as defined in (1) and $d_{t}$ denotes the current circuit depth, weighted by the $\beta$ hyperparameter, which is fixed at 0.015 in our experiments. This reward is straightforward and directly tied to the quality of the circuit built at time step $t$ : the first term incentivizes the minimization of $\langle H\rangle^{*}$, which is our primary goal, while the second term drives the agent to prefer shallower circuits, which are more resilient to noise and qubit decoherence. It is worth noting that in this phase the circuit depth is computed after expressing the circuits in terms of

[^0]
[^0]:    ${ }^{1}$ We use the SciPy implementation of COBYLA, keeping its default hyperparameters. The documentation is available here: https://docs.scipy.org/ doc/scipy/reference/optimize.minimize-cobyla.html
    ${ }^{2}$ Circuit simulation is performed using Qiskit QASM Simulator. The documentation is available here: https://qiskit.github.io/qiskit-aer/stubs/qiskit_ aer.QasmSimulator.htmlthe basis gates $\left\{H, R_{x}, R_{y}, R_{z}, R_{z z}\right\}$. In particular, while the double rotation $R_{z z}$ is directly used, the others are represented in terms of it. Finally, we remark that designing an effective reward function that combines different goals is again a critical aspect in RL which allows for great flexibility. Moreover, it is important to highlight that the suitability of a particular reward function may vary depending on the nature of the task and specific requirements.

A complete visual overview of the RL pipeline with a detailed description of the agent and environment is represented in Fig. 1.

## B. Training Details

RLVQC uses the version of PPO implemented as described by OpenAI [52], [53], with default hyperparameters. This implementation employs two multi-layer fully-connected neural networks, each sharing the same structure but with separate learnable parameters, for the policy and value network. With the problem size denoted as $n$, the input layer of each neural network comprises $2^{n}$ neurons, matching the size of the vector representing the environment state (see Section IV-A). The output layer for the policy network has size $|\mathcal{A}|$, which depends on the number of problem variables. Agent training comprises 64 epochs, with each epoch being a collection of 384 action steps ${ }^{3}$ after which the parameters of the PPO's neural networks are updated. Each epoch consists of multiple episodes, each starting from a circuit with only Hadamard gates and ending when a termination condition is met. Specifically, an episode terminates either when a maximum of $2 \cdot n$ actions have been performed or earlier, if the reward does not improve with new actions. The latter mechanism is controlled by the patience hyperparameter. Patience is initially set to 3 and decreases every time a step ends with a worse reward than the highest found during the current episode. Otherwise, it is increased, but only up to its initial value. Stopping the episode earlier avoids spending time steps on actions that are unlikely to improve the reward. Throughout training, we keep track of the circuit with the highest reward, which is then analyzed after training is completed.

## C. Problem Instances

In our experiments, we evaluate RLVQC on the task of finding the solution of optimization problems that can be formulated as Quadratic Unconstrained Binary Optimization (QUBO) problems [63]. The general formulation of a QUBO problem is the following:

$$
\min _{x \in\{0,1\}^{n}} x^{T} \mathbf{Q} x
$$

where $x=\left\{x_{1}, \ldots, x_{n}\right\} \in\{0,1\}^{n}$ and $\mathbf{Q}$ denotes an upper triangular or symmetrical $n \times n$ matrix. QUBO problems can be expressed as equivalent Ising problems through a change of variable [64]. Leveraging this formulation, the objective becomes to identify the ground state of a Hamiltonian operator, a task which can be accomplished using our algorithm RLVQC.

[^0]
(a) Interaction between agent and environment. At time step $t$ the agent observes the environment's state $s_{t}$ and acts with action $a_{t}$ on the environment, which gives reward $r_{t}$ to the agent. At the next time step, the agent will observe the new state $s_{t+1}$.

(b) State $s_{t}$ is processed by the agent's neural networks. The value network outputs an estimate $\hat{V}_{\pi}\left(s_{t}\right)$ of the value function (4), while the policy network outputs a probability distribution $\pi\left(a \mid s_{t}\right)$ on the actions. Action $a_{t}$ is sampled from this probability distribution.

(c) When the environment receives action $a_{t}$, the corresponding gate is added to the circuit. Then, its parameters are optimized and the circuit is simulated to obtain the next state $s_{t+1}$, which is sent back to the agent with the corresponding reward $r_{t}$.

Fig. 1: Visual overview of the RL pipeline, describing the interaction between agent and environment (see 1a) and how the agent (see 1b) and environment (see 1c) work internally.


[^0]:    ${ }^{3}$ This number is obtained by having multiple processes performing 64 action steps each in our default implementation.We address three diverse optimization problem types: Maximum Cut, Maximum Clique, and Minimum Vertex Cover, all formulated as QUBO problems. [63], [65]. It is important to highlight that Minimum Vertex Cover and Maximum Clique involve constraints. To incorporate these constraints into the QUBO formulation, penalty terms are directly integrated into the cost functions. Each penalty term is a function that yields a value of 1 when a constraint is violated and 0 when it is satisfied, multiplied by a weight coefficient. These coefficients are chosen to ensure that all the feasible solutions have a lower expectation than the infeasible ones, thereby guiding the algorithm towards favoring feasible solutions over infeasible ones. For each problem type, we consider three different graph topologies:

- 3-regular, a graph where each vertex is connected to exactly three neighbors;
- 2D-grid, a two-dimensional integer lattice graph where each vertex can have up to 4 neighbours;
- Star graph, characterized by one central node connected to all other nodes, with no further connections among the non-central nodes.
For each problem type, we explore graphs with $n=8$ and $n=14$ vertices across each topology, resulting in a total of 18 trained agents.


## D. Evaluation Metrics

Our main goal is to assess whether it is possible to use a RL agent to discover ansatzes capable of sampling high-quality solutions to optimization problems. We aim to evaluate both the accuracy of the solutions found and the characteristics of the resulting circuits. To this purpose, the most relevant metric we use is the approximation ratio (A.R.), defined as:

$$
\text { A.R. }=\frac{\langle H\rangle^{*}-\langle H\rangle_{\max }}{\langle H\rangle_{\min }-\langle H\rangle_{\max }}
$$

where $\langle H\rangle_{\min }$ and $\langle H\rangle_{\max }$ represent the minimum and maximum values of the achievable expectations, respectively, and $\langle H\rangle^{*}$ is an estimate of the expectation, as defined in (1). The intuition behind this metric is that the ratio $\frac{\langle H\rangle^{*}}{\langle H\rangle_{\min }}$ approaches 1 when $\langle H\rangle^{*}$ closely approximates $\langle H\rangle_{\min }$, indicating that the circuit allows to sample with high probability states whose energy values are close to the minimum. To guarantee that both the numerator and the denominator of the ratio have negative values, we subtract $\langle H\rangle_{\max }$ from both quantities. This ensures that the final approximation ratio falls between 0 and 1 , with closer proximity to 1 when the solution quality is higher. It is worth noting that in the case of the Maximum Cut problem, $\langle H\rangle_{\max }=0$.

However, the approximation ratio alone does not indicate if the constraints in Minimum Vertex Cover and Maximum Clique are satisfied. Hence, in Table I, we include a threshold corresponding to the lowest approximation ratio of feasible solutions. Circuits with approximation ratios below this threshold are more likely to sample infeasible solutions. Notice that, for the unconstrained Maximum Cut problem, the feasibility threshold is 0 .

Finally, we analyze the composition of the final circuit, reporting the number of single and two-qubit gates, as well as the circuit depth. These metrics are computed after expressing the circuit in terms of the gates $\left\{C x, R_{x}, R_{y}, R_{z}\right\}$, where $C x$ denotes the CNOT gate, and and applying some simplifications using the Qiskit transpiler with optimization level 1, which is the default setting.

## V. ReSults and DiSCuSSION

In this section, we discuss the results obtained by executing the RLVQC algorithm according to the experimental protocol outlined in Section IV, using the metrics detailed in Section IV-D. To establish a baseline for comparison, we also run QAOA with $p=1$ on the same problem instances and analyze the same set of metrics. Since QAOA is a stochastic algorithm which strictly depends on the initial parameters, we perform 10 executions of the algorithm for each problem instance. We choose random initial parameters for each run, and then average the approximation ratios obtained. This comparative analysis is presented in Section V-A.

Notably, during training on the Maximum Cut problem, the agent discovered circuits with a common structure and high approximation ratios. This observation led us to identify a novel family of ansatzes, which we denote as $R_{y z^{-}}$ connected circuits, as discussed in Section V-B. In particular, we conduct an analysis of the most intuitive circuit within this family, which we refer to as Linear circuit, by examining its performance across a broader set of graph topologies and different problem types. Finally, in Section V-C, we discuss the straightforward implementability of the $R_{y z}$-connected circuits.

## A. RLVQC Results

In Table I we report the results relative to the solutions and circuits found with RLVQC and QAOA with $p=1$ in terms of the metrics described in Section IV-D. Specifically, the table shows the approximation ratio (A.R.) of the solutions, the approximation ratio threshold (A.R. Thresh.) for feasibility, the number of single and two-qubit gates, and the circuit depth.

By examining Table I, it can be noticed that the approximation ratios found by RLVQC is significantly influenced by the type of optimization problem being addressed. RLVQC consistently outperforms QAOA in Maximum Cut and Minimum Vertex Cover instances, with one exception observed in the case of the star-topology graph instances with $n=14$ vertices for both problem types, where RLVQC performs worse. Moreover, for the Minimum Vertex Cover instance with star-topology and $n=14$, RLVQC falls below the threshold for feasibility in terms of approximation ratio. The particularly strong performance of RLVQC on Maximum Cut instances, especially on instances with $n=8$ qubits where RLVQC consistently achieves an approximation ratio of 0.99 , prompted us to conduct a deeper analysis of these circuits. Interestingly, we observed that the agent exclusively added $R_{y z}$ rotations to these circuits during their construction, without performing any single-qubit actions. This observation suggests that circuits| Size | Problem | Graph | A.R. | | A.R. Thresh. | Single-qubit | | Two-qubit | | Depth | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| | | | RLVQC | QAOA | | RLVQC | QAOA | RLVQC | QAOA | RLVQC | QAOA |
| 8 | Maximum Cut | 3-regular | 0.99 | 0.75 | 0.00 | 37 | 36 | 14 | 24 | 38 | 12 |
| | | 2D-grid | 0.99 | 0.63 | 0.00 | 37 | 34 | 14 | 20 | 38 | 12 |
| | | Star graph | 0.99 | 0.70 | 0.00 | 37 | 31 | 14 | 14 | 38 | 24 |
| | Maximum Clique | 3-regular | 0.75 | 0.81 | 0.91 | 62 | 48 | 22 | 32 | 40 | 15 |
| | | 2D-grid | 0.83 | 0.78 | 0.94 | 47 | 50 | 20 | 36 | 43 | 15 |
| | | Star graph | 0.70 | 0.80 | 0.95 | 44 | 53 | 18 | 42 | 38 | 21 |
| | Minimum Vertex Cover | 3-regular | 0.99 | 0.83 | 0.77 | 63 | 44 | 18 | 24 | 43 | 12 |
| | | 2D-grid | 0.96 | 0.85 | 0.73 | 28 | 42 | 6 | 20 | 16 | 12 |
| | | Star graph | 0.93 | 0.83 | 0.69 | 31 | 39 | 8 | 14 | 20 | 24 |
| 14 | Maximum Cut | 3-regular | 0.92 | 0.74 | 0.00 | 67 | 63 | 26 | 42 | 56 | 12 |
| | | 2D-grid | 0.76 | 0.65 | 0.00 | 64 | 61 | 24 | 38 | 52 | 12 |
| | | Star graph | 0.50 | 0.71 | 0.00 | 49 | 55 | 14 | 26 | 32 | 42 |
| | Maximum Clique | 3-regular | 0.64 | 0.79 | 0.98 | 80 | 126 | 26 | 140 | 48 | 34 |
| | | 2D-grid | 0.72 | 0.78 | 0.99 | 78 | 128 | 24 | 144 | 35 | 34 |
| | | Star graph | 0.63 | 0.76 | 0.99 | 97 | 134 | 34 | 156 | 55 | 39 |
| | Minimum Vertex Cover | 3-regular | 0.85 | 0.78 | 0.74 | 87 | 77 | 28 | 42 | 54 | 12 |
| | | 2D-grid | 0.87 | 0.87 | 0.74 | 72 | 75 | 18 | 38 | 33 | 12 |
| | | Star graph | 0.65 | 0.82 | 0.71 | 55 | 69 | 14 | 26 | 32 | 42 |

TABLE I: Comparative analysis of the performance of RLVQC and QAOA with $p=1$ on instances of different problem types built from graph with various topologies and $n=8$ and $n=14$ vertices. The table reports the approximation ratios relative to the circuits with the highest reward found by RLVQC and the average approximation ratio reached by QAOA across 10 executions of the algorithm, along with the threshold for feasibility. Additionally, the table shows the number of single-qubit and two-qubit gates, as well as the circuit depth.
containing $R_{y z}$ rotations may be particularly effective for addressing Maximum Cut problems. In contrast, for Maximum Clique instances, RLVQC consistently yields lower approximation ratios compared to QAOA, except for the instance built from a 2D-grid-topology graph with $n=8$ vertices. However, neither algorithm attains satisfactory results, as the threshold for feasibility is never met for any graph topology.

Upon analyzing the count of single and two-qubit gates, as well as the circuit depth, we observe that RLVQC generally employs a number of gates comparable to QAOA but exhibits a higher depth. Notably, there are cases where the RLVQC circuit has a gate count that is significantly lower than in QAOA, yet the depth increases. An example is given by Maximum Clique with $n=14$, where the count of two-qubit gates amounts to less than $25 \%$ of the two-qubit gates used by QAOA. Finally, it is important to notice that, while circuits produced by RLVQC tend to have higher depth compared to QAOA, adjusting the $\beta$ hyperparameter in the reward function (8) allows for further penalizing deep circuits. This adjustment may guide RLVQC toward the preference of lowdepth circuits.

In summary, RLVQC successfully found solutions with approximation ratios comparable to QAOA, or superior in the case of the Maximum Cut problem. It is noteworthy that these results are obtained using a relatively straightforward design for the RL agent, environment and reward. Therefore, there is a considerable potential to further improve these results by better understanding how to design these components for quantum computing tasks.

## B. $R_{y z}$-connected Ansatzes

Here we describe the family of $R_{y z}$-connected ansatzes discovered during training on the Maximum Cut problem. This family is composed of circuits with an initial layer of Hadamard gates, followed by $n-1 R_{y z}$ rotations, which are applied such that each new $R_{y z}$ adds only one qubit to the "chain" of connected qubits. More formally, calling $C_{j}$ the graph representing the connectivity of the circuit after applying the first $j R_{y z}$ rotations, the $C_{j}$ graphs associated to each $R_{y z^{-}}$ connected ansatz are connected for all $j=1, \ldots, n-1$.

Recall that a $R_{z z}$ gate is equivalent to two $C x$ gates with a $R_{z}$ rotation between them on the target qubit, as shown below:


Using the more general definition of double rotations provided in (7) and the above expansion of the $R_{z z}$ gate, we have that $R_{y z}$ rotations can be decomposed as follows:


A notable property of $R_{y z}$-connected circuits is that two basis states that have all bits flipped w.r.t. to one another have the same probability of being measured. This characteristic makes the circuits especially well-suited for problems that possess this symmetry property, such as the Maximum Cut problem.Among the elements of the $R_{y z}$-connected family, we focus on a specific circuit, which we denote as Linear circuit, where each $R_{y z}$ gate connects one qubit to the next one (see Fig. 2). It is worth noting that each block of the figure represents the decomposition of a $R_{y z}$ gate as explained in Section V-B. The first $R_{x}\left(\frac{\pi}{2}\right)$ gate is omitted since it behaves as the identity when applied after a Hadamard gate. The choice of analyzing this particular $R_{y z}$-connected ansatz is motivated by its uniform application of $R_{y z}$ gates across all qubits, making it the most straightforward configuration within the family.

The primary objective of our analysis is to evaluate the quality of solutions obtained by the Linear circuit on the Maximum Cut problem, but across a broader range of underlying graph topologies. We maintain the use of 3-regular, 2D-grid, and star graphs, and further include cycle graphs, where each vertex is connected to exactly two other vertices, forming a closed loop. Additionally, we introduce Erdős-Rényi graphs generated from a set of vertices, with edges independently connected based on fixed probabilities of 0.2, 0.5, and 0.8. Subsequently, we evaluate the performance of the Linear circuit on other problem types, specifically Maximum Clique and Minimum Vertex Cover, using the same underlying topologies. The algorithms are tested on instances with 8, 14, and 16 vertices, which represents the largest tractable size with our available hardware. However, we present results only for the 16-vertex instances, as the findings for smaller instances are analogous. We compare the performance of the Linear circuit with state-of-the-art quantum algorithms, including QAOA with depths $p=1$ and $p=2$, QAOA+, and ma-QAOA (see Section II). Each algorithm is executed 10 times on each problem instance and the results are averaged. We choose random initial parameters for each execution.

Fig. 3 represents the average approximation ratios obtained by executing the algorithms on the Maximum Cut problem across diverse graph topologies, as described above. A notable observation is that the Linear circuit often achieves the best approximation ratio. However, there are exceptions, such as the Erdős-Rényi random graph with an edge probability of 0.2 , where the Linear circuit performs slightly worse than QAOA with $p=2$. Moreover, on the star-topology graph, the approximation ratio obtained by the Linear circuit is significantly lower than that obtained by all other algorithms. We believe that further investigation into the cause of this behavior can be useful.

In contrast, when applying the same algorithms to Maximum Clique and Minimum Vertex Cover problems, we observe that the approximation ratios of the Linear circuit are lower than those achieved by the other algorithms. Among the algorithms tested, QAOA with $p=2$ consistently achieves the highest approximation ratio across all graph topologies, except for the Erdős-Rényi graphs with edge probabilities of 0.5 and 0.8 , where QAOA with $p=1$ and ma-QAOA perform the best, respectively. These findings support our observation that $R_{y z}$-connected ansatzes are suitable for problems where the cost of a solution remains the same if all bits are flipped, which include Maximum Cut, but not Maximum Clique and

Minimum Vertex Cover problems.
In order to better understand why the Linear ansatz achieves higher approximation ratios compared to other algorithms, we conduct an analysis of the final distribution of states obtained by the Linear circuit after its parameter optimization comparing it to QAOA with $p=1$ with 1000 shots, when applied to the Maximum Cut problem. Specifically, we perform a single execution of both algorithms on the same problem instance and examine the distribution of solutions associated with the circuits with optimal parameters. Fig. 4 illustrates these distributions obtained on a Maximum Cut instance constructed from a $n=16$ vertices Erdős-Rényi graph with edge probability 0.5 . A notable observation is that the distribution of solutions produced by the Linear circuit is more concentrated on solutions with lower costs. This concentration is advantageous for achieving high approximation ratios according to our definition. Conversely, the distribution of solutions generated by QAOA is more spread across the solution space, making this algorithm more suited for exploration purposes.

Overall, we can conclude that RLVQC was able to find a reasonable ansatz, consistently capable of finding higher approximation ratios than other quantum state-of-the-art algorithms.

## C. Implementability of $R_{y z}$-connected Ansatzes

In this subsection we discuss the ease of implementability of the $R_{y z}$-connected ansatzes on specific real quantum devices. In modern technologies, $R_{z}$ rotations can be implemented with negligible error and time for any rotation angle [66], while implementing a $R_{x}$ rotation requires a specific application time. Since any arbitrary rotation can be achieved by combining $R_{z}$ and $R_{x}\left(\frac{\pi}{2}\right)$ rotations, superconducting computers are often calibrated to perform only $R_{z}$ and $R_{x}\left(\frac{\pi}{2}\right)$ rotations, and not the full set of $R_{x}$ rotations. Our $R_{y z}$-connected ansatzes are very good in such a framework, since we can observe that the $R_{y z}$ rotations can be decomposed into $R_{z}$ and $R_{x}\left(-\frac{\pi}{2}\right)$ rotations, and $C x$ gates. In particular, the only single-qubit parametric gates are the $R_{z}$ rotations, which can be executed virtually without error. Additionally, to implement the $R_{x}\left(-\frac{\pi}{2}\right)$ rotations, we can substitute each of these gates with a $R_{x}\left(\frac{\pi}{2}\right) . R_{y z}$-connected ansatzes maintain their performance after this substitution, allowing us to exploit the calibration of the hardware.

Moreover, the $R_{y z}$-connected family offers advantages when mapping the logic circuit to the quantum device topology. Specifically, we can select a particular element of the $R_{y z}$-connected ansatzes based on the connectivity of the available hardware. This approach reduces the number of SWAP gates required to connect qubits that are connected in the logical circuit but not in the hardware. This approach results in resource savings and reduces errors caused by an increased number of gates and circuit depth.

## VI. CONCLUSIONS AND FUTURE DIRECTIONS

In this study, we introduced RLVQC, a Reinforcement Learning algorithm designed to learn how to construct quan-

Fig. 2: Linear circuit, a specific element of the family of R<sub>yz</sub>-connected ansatzes found during training on Maximum Cut.



Fig. 3: Approximation Ratio obtained by the tested quantum algorithms on Maximum Cut instances on graphs with 16 vertices.



Fig. 4: Comparison of solution distributions in circuits with optimal parameters solving the Maximum Cut problem on a n = 16 vertices Erdős–Rényi graph with edge probability 0.8. Results are obtained using the Linear circuit and QAOA with p = 1 with their parameter optimized, each executed with 1000 shots. The x-axis displays cost values of the QUBO formulation cost function, while the y-axis shows the frequency of each cost occurrence within the total shots.

tum circuits to solve optimization problems through a quantum variational approach. Overall, RLVQC demonstrated its ability to build circuits able to generate solutions with approximation ratios comparable to those obtained by QAOA, and particularly high in the case of the Maximum Cut problem.

Furthermore, we analyzed the R<sub>yz</sub>-connected ansatzes, a specific family of circuits discovered by the agent during its training on the Maximum Cut problem. Our investigation revealed that the R<sub>yz</sub>-connected ansatzes can achieve high approximation ratios, superior to those obtained with other state-of-the-art algorithms on Maximum Cut instances.

These results suggest that approaches employing Reinforcement Learning agents to construct variational circuits hold promise. Given the flexibility of RL, there is potential for future research aimed at improving each of the components of RLVQC, including the representation of the environment's state, the agent's network architecture, the action set, and the reward function. Each of these elements may be designed, for example, to take advantage of the peculiarities of a given problem, a specific hardware or even adapt to the requirements set by the task at hand. More generally, RL looks promising for researchers aiming to address challenges characterized by large solution spaces within the quantum computing domain.

### ACKNOWLEDGMENT

We acknowledge the financial support from ICSC - "National Research Centre in High Performance Computing, Big Data and Quantum Computing", funded by European Union – NextGenerationEU. We also acknowledge the support and computational resources provided by E4 Computer Engineering S.p.A.

### REFERENCES

- [1] M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin, S. Endo, K. Fujii, J. R. McClean, K. Mitarai, X. Yuan, L. Cincio, and P. J. Coles, "Variational quantum algorithms," *Nature Reviews Physics*, vol. 3, no. 9, p. 625–644, Aug. 2021. [Online]. Available: http://dx.doi.org/10.1038/s42254-021-00348-9
- [2] J. Preskill, "Quantum computing in the nisq era and beyond," *Quantum*, vol. 2, p. 79, Aug. 2018. [Online]. Available: http://dx.doi.org/10.22331/q-2018-08-06-79[3] J. J. Meyer, M. Mularski, E. Gil-Fuster, A. A. Mele, F. Arzani, A. Wilms, and J. Eisert, "Exploiting symmetry in variational quantum machine learning," PRX Quantum, vol. 4, p. 010328, Mar 2023. [Online]. Available: https://link.aps.org/doi/10.1103/PRXQuantum.4.010328
[4] I. N. M. Le, O. Kiss, J. Schuhmacher, I. Tavernelli, and F. Tacchino, "Symmetry-invariant quantum machine learning force fields," 2023.
[5] D. Wierichs, R. D. P. East, M. Larocca, M. Cerezo, and N. Killoran, "Symmetric derivatives of parametrized quantum circuits," 122023.
[6] G. Turati, M. Ferrari Dacrema, and P. Cremonesi, "Benchmarking adaptative variational quantum algorithms on qubo instances," in 2023 IEEE International Conference on Quantum Computing and Engineering (QCE), vol. 01, 2023, pp. 407-413.
[7] D. Claudino, J. Wright, A. J. McCaskey, and T. S. Humble, "Benchmarking adaptive variational quantum eigensolvers," Frontiers in Chemistry, vol. 8, 2020. [Online]. Available: https://www.frontiersin. org/articles/10.3389/fchem.2020.606863
[8] A. Mukherjee, N. F. Berthusen, J. C. Getelina, P. P. Orth, and Y.-X. Yao, "Comparative study of adaptive variational quantum eigensolvers for multi-orbital impurity models," Communications Physics, vol. 6, no. 1, p. 4, 2023. [Online]. Available: https: //doi.org/10.1038/s42005-022-01089-6
[9] M. M. Wauters, E. Panizon, G. B. Mbeng, and G. E. Santoro, "Reinforcement-learning-assisted quantum optimization," Phys. Rev. Res., vol. 2, p. 033446, Sep 2020. [Online]. Available: https: //link.aps.org/doi/10.1103/PhysRevResearch.2.033446
[10] S. Khairy, R. Shaydulin, L. Cincio, Y. Alexeev, and P. Balaprakash, "Learning to optimize variational quantum circuits to solve combinatorial problems," Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 03, p. 2367-2375, Apr. 2020. [Online]. Available: http://dx.doi.org/10.1609/aaai.v34i03.5616
[11] J. Yao, M. Bukov, and L. Lin, "Policy gradient based quantum approximate optimization algorithm," 2020.
[12] M. Pirhoushyaran and T. Terlaky, "Quantum circuit design search," Quantum Machine Intelligence, vol. 3, no. 2, p. 25, 2021. [Online]. Available: https://doi.org/10.1007/s42484-021-00051-z
[13] M. Ostaszewski, L. M. Trenkwalder, W. Masarczyk, E. Scerri, and V. Dunjko, "Reinforcement learning for optimization of variational quantum circuit architectures," in Advances in Neural Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, Eds., vol. 34. Curran Associates, Inc., 2021, pp. 18 18218 194. [Online]. Available: https://proceedings.neurips.cc/paper_files/ paper/2021/file/9724412729185d53a2e3e7f889d9f057-Paper.pdf
[14] A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q. Zhou, P. J. Love, A. Aspuru-Guzik, and J. L. O'Brien, "A variational eigenvalue solver on a photonic quantum processor," Nature Communications, vol. 5, no. 1, Jul. 2014. [Online]. Available: http://dx.doi.org/10.1038/ ncomms5213
[15] J. Tilly, H. Chen, S. Cao, D. Picozzi, K. Setia, Y. Li, E. Grant, L. Wossnig, I. Rungger, G. H. Booth, and J. Tennyson, "The variational quantum eigensolver: A review of methods and best practices," Physics Reports, vol. 986, pp. 1-128, 2022, the Variational Quantum Eigensolver: a review of methods and best practices. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0370157322003118
[16] Y. Cao, J. Romero, J. P. Olson, M. Degroote, P. D. Johnson, M. Kieferová, I. D. Kivlichan, T. Menke, B. Peropadre, N. P. D. Sawaya, S. Sim, L. Veis, and A. Aspuru-Guzik, "Quantum chemistry in the age of quantum computing," Chemical Reviews, vol. 119, no. 19, pp. 10.856-10 915, 2019, pMID: 31469277. [Online]. Available: https://doi.org/10.1021/acs.chemrev.8b00803
[17] J. R. McClean, J. Romero, R. Babbush, and A. Aspuru-Guzik, "The theory of variational hybrid quantum-classical algorithms," New Journal of Physics, vol. 18, no. 2, p. 023023, feb 2016. [Online]. Available: https://dx.doi.org/10.1088/1367-2630/18/2/023023
[18] E. Farhi, J. Goldstone, and S. Gutmann, "A quantum approximate optimization algorithm," 2014.
[19] K. Blekro, D. Brand, A. Ceschini, C.-H. Chou, R.-H. Li, K. Pandya, and A. Summer, "A review on quantum approximate optimization algorithm and its variants," 2023.
[20] G. E. Crooks, "Performance of the quantum approximate optimization algorithm on the maximum cut problem," 2018.
[21] M. Willsch, D. Willsch, F. Jin, H. D. Raedt, and K. Michielsen, "Benchmarking the quantum approximate optimization algorithm," Quantum Information Processing, vol. 19, no. 7, jun 2020. [Online]. Available: https://doi.org/10.1007%2Fs11128-020-02692-8
[22] J. Cook, S. Eidenbenz, and A. Bärtschi, "The quantum alternating operator ansatz on maximum k-vertex cover," in 2020 IEEE International Conference on Quantum Computing and Engineering (QCE), 2020, pp. 83-92.
[23] C. Y.-Y. Lin and Y. Zhu, "Performance of qaoa on typical instances of constraint satisfaction problems with bounded degree," 2016.
[24] M. Radzihovsky, J. Murphy, and M. Swofford, "A qaoa solution to the traveling salesman problem using pyquil," 2019.
[25] S. Brandhofer, D. Braun, V. Dehn, G. Hellstern, M. Hüls, Y. Ji, I. Polian, A. S. Bhatia, and T. Wellens, "Benchmarking the performance of portfolio optimization with qaoa," Quantum Information Processing, vol. 22, no. 1, p. 25, Dec 2022. [Online]. Available: https://doi.org/10.1007/s11128-022-03766-5
[26] K. Kurowski, T. Pecyna, M. Slysz, R. Różycki, G. Waligóra, and J. Weglarz, "Application of quantum approximate optimization algorithm to job shop scheduling problem," European Journal of Operational Research, vol. 310, no. 2, pp. 518-528, 2023. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0377221723002072
[27] R. Herrman, P. C. Lotshaw, J. Ostrowski, T. S. Humble, and G. Siopsis, "Multi-angle quantum approximate optimization algorithm," Scientific Reports, vol. 12, no. 1, p. 6781, 2022. [Online]. Available: https://doi.org/10.1038/s41598-022-10555-8
[28] M. Chalupnik, H. Melo, Y. Alexeev, and A. Galda, "Augmenting qaoa ansatz with multiparameter problem-independent layer," in 2022 IEEE International Conference on Quantum Computing and Engineering (QCE). Los Alamitos, CA, USA: IEEE Computer Society, sep 2022, pp. 97-103. [Online]. Available: https://doi.ieeecomputersociety.org/10. 1109/QCE53715.2022.00028
[29] S. Sim, P. D. Johnson, and A. Aspuru-Guzik, "Expressibility and entangling capability of parameterized quantum circuits for hybrid quantum-classical algorithms," Advanced Quantum Technologies, vol. 2, no. 12, p. 1900070, 2019. [Online]. Available: https: //onlinelibrary.wiley.com/doi/abs/10.1002/qute. 201900070
[30] J. Qin, "Review of ansatz designing techniques for variational quantum algorithms," Journal of Physics: Conference Series, vol. 2634, no. 1, p. 012043, nov 2023. [Online]. Available: https: //dx.doi.org/10.1088/1742-6596/2634/1/012043
[31] J. Wurtz and P. J. Love, "Classically optimal variational quantum algorithms," IEEE Transactions on Quantum Engineering, vol. 2, pp. $1-7,2021$.
[32] Y. Du, M.-H. Hsieh, T. Liu, and D. Tao, "Expressive power of parametrized quantum circuits," Phys. Rev. Res., vol. 2, p. 033125, Jul 2020. [Online]. Available: https://link.aps.org/doi/10.1103/ PhysRevResearch.2.033125
[33] J. R. McClean, S. Boixo, V. N. Smelyanskiy, R. Babbush, and H. Neven, "Barren plateaus in quantum neural network training landscapes," Nature Communications, vol. 9, no. 1, Nov. 2018. [Online]. Available: http://dx.doi.org/10.1038/s41467-018-07090-4
[34] A. Arrasmith, M. Cerezo, P. Czarnik, L. Cincio, and P. J. Coles, "Effect of barren plateaus on gradient-free optimization," Quantum, vol. 5, p. 558, Oct. 2021. [Online]. Available: https: //doi.org/10.22331/q-2021-10-05-558
[35] A. Arrasmith, Z. Holmes, M. Cerezo, and P. J. Coles, "Equivalence of quantum barren plateaus to cost concentration and narrow gorges," Quantum Science and Technology, vol. 7, no. 4, p. 045015, aug 2022. [Online]. Available: https://dx.doi.org/10.1088/2058-9565/ac7d06
[36] M. Cerezo and P. J. Coles, "Higher order derivatives of quantum neural networks with barren plateaus," Quantum Science and Technology, vol. 6, no. 3, p. 035006, jun 2021. [Online]. Available: https://dx.doi.org/10.1088/2058-9565/abf51a
[37] Z. Holmes, K. Sharma, M. Cerezo, and P. J. Coles, "Connecting ansatz expressibility to gradient magnitudes and barren plateaus," PRX Quantum, vol. 3, p. 010313, Jan 2022. [Online]. Available: https://link.aps.org/doi/10.1103/PRXQuantum.3.010313
[38] M. Larocca, P. Czarnik, K. Sharma, G. Muraleedharan, P. J. Coles, and M. Cerezo, "Diagnosing Barren Plateaus with Tools from Quantum Optimal Control," Quantum, vol. 6, p. 824, Sep. 2022. [Online]. Available: https://doi.org/10.22331/q-2022-09-29-824
[39] T. Volkoff and P. J. Coles, "Large gradients via correlation in random parameterized quantum circuits," Quantum Science and Technology, vol. 6, no. 2, p. 025008, jan 2021. [Online]. Available: https://dx.doi.org/10.1088/2058-9565/abd891
[40] H. R. Grimsley, S. E. Economou, E. Barnes, and N. J. Mayhall, "An adaptive variational algorithm for exact molecular simulationson a quantum computer," Nature Communications, vol. 10, no. 1, p. 3007, July 2019. [Online]. Available: https://doi.org/10.1038/ s41467-019-10988-2
[41] H. L. Tang, V. Shkolnikov, G. S. Barron, H. R. Grimsley, N. J. Mayhall, E. Barnes, and S. E. Economou, "Qubit-ADAPT-VQE: An adaptive algorithm for constructing hardware-efficient ansätze on a quantum processor," PRS Quantum, vol. 2, no. 2, apr 2021. [Online]. Available: https://doi.org/10.1103\%2Fprxquantum.2.020310
[42] Y. S. Yordanov, V. Armaos, C. H. W. Barnes, and D. R. M. Arvidsson-Shukur, "Qubit-excitation-based adaptive variational quantum eigensolver," Communications Physics, vol. 4, no. 1, oct 2021. [Online]. Available: https://doi.org/10.1038\%2Fs42005-021-00730-0
[43] C. Feniou, M. Hassan, D. Traoré, E. Giner, Y. Maday, and J.-P. Piquemal, "Overlap-adapt-vqe: practical quantum chemistry on quantum computers via overlap-guided compact ansätze," Communications Physics, vol. 6, no. 1, p. 192, 07 2023. [Online]. Available: https://doi.org/10.1038/s42005-023-01312-y
[44] L. Zhu, H. L. Tang, G. S. Barron, F. A. Calderon-Vargas, N. J. Mayhall, E. Barnes, and S. E. Economou, "Adaptive quantum approximate optimization algorithm for solving combinatorial problems on a quantum computer," Phys. Rev. Res., vol. 4, p. 033029, Jul 2022. [Online]. Available: https://link.aps.org/doi/10.1103/PhysRevResearch.4.033029
[45] A. G. Rattew, S. Hu, M. Pistoia, R. Chen, and S. Wood, "A domain-agnostic, noise-resistant, hardware-efficient evolutionary variational quantum eigensolver," 2020.
[46] D. Chivilikhin, A. Samarin, V. Ulyantsev, I. Iorsh, A. R. Oganov, and O. Kyriienko, "Mog-vqe: Multiobjective genetic variational quantum eigensolver," 2020.
[47] U. Las Heras, U. Alvarez-Rodriguez, E. Solano, and M. Sanz, "Genetic algorithms for digital quantum simulations," Phys. Rev. Lett., vol. 116, p. 230504, Jun 2016. [Online]. Available: https: //link.aps.org/doi/10.1103/PhysRevLett.116.230504
[48] L. Cincio, Y. Subaşı, A. T. Sornborger, and P. J. Coles, "Learning the quantum algorithm for state overlap," New Journal of Physics, vol. 20, no. 11, p. 113022, nov 2018. [Online]. Available: https://dx.doi.org/10.1088/1367-2630/aaer94a
[49] Y. Du, T. Huang, S. You, M.-H. Hsieh, and D. Tao, "Quantum circuit architecture search for variational quantum algorithms," npj Quantum Information, vol. 8, no. 1, p. 62, May 2022. [Online]. Available: https://doi.org/10.1038/s41534-022-00570-y
[50] M. Bilkis, M. Cerezo, G. Verdon, P. J. Coles, and L. Cincio, "A semi-agnostic ansatz with variable structure for variational quantum algorithms," Quantum Machine Intelligence, vol. 5, no. 2, p. 43, November 2023. [Online]. Available: https://doi.org/10.1007/ s42484-023-00132-1
[51] R. S. Sutton and A. G. Barto, Reinforcement learning - an introduction, ser. Adaptive computation and machine learning. MIT Press, 1998. [Online]. Available: https://www.worldcat.org/oclc/37293240
[52] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, "Proximal policy optimization algorithms," CoRR, vol. abs/1707.06347, 2017. [Online]. Available: http://arxiv.org/abs/1707.06347
[53] J. Achiam, "Spinning Up in Deep Reinforcement Learning," 2018.
[54] S. Giordano and M. A. Martin-Delgado, "Reinforcement-learning generation of four-qubit entangled states," Phys. Rev. Res., vol. 4, p. 043056, Oct 2022. [Online]. Available: https://link.aps.org/doi/10.1103/ PhysRevResearch.4.043056
[55] E.-J. Kuo, Y.-L. L. Fang, and S. Y.-C. Chen, "Quantum architecture search via deep reinforcement learning," 2021.
[56] X. Zhu and X. Hou, "Quantum architecture search via truly proximal policy optimization," Scientific Reports, vol. 13, no. 1, p. 5157, 2023. [Online]. Available: https://doi.org/10.1038/s41598-023-32349-2
[57] L. Moro, M. G. A. Paris, M. Restelli, and E. Prati, "Quantum compiling by deep reinforcement learning," Communications Physics, vol. 4, no. 1, p. 178, 08 2021. [Online]. Available: https: //doi.org/10.1038/s42005-021-00684-3
[58] Y.-H. Zhang, P.-L. Zheng, Y. Zhang, and D.-L. Deng, "Topological quantum compiling with reinforcement learning," Phys. Rev. Lett., vol. 125, p. 170501, Oct 2020. [Online]. Available: https://link.aps.org/doi/ 10.1103/PhysRevLett.125.170501
[59] T. Fosel, M. Y. Niu, F. Marquardt, and L. Li, "Quantum circuit optimization with deep reinforcement learning," 2021. [Online]. Available: https://api.semanticscholar.org/CorpusID:232233792
[60] E. Grant, L. Wossnig, M. Ostaszewski, and M. Benedetti, "An initialization strategy for addressing barren plateaus in parametrized
quantum circuits," Quantum, vol. 3, p. 214, Dec. 2019. [Online]. Available: http://dx.doi.org/10.22331/q-2019-12-09-214
[61] H. Singh, S. Majumder, and S. Mishra, "Benchmarking of different optimizers in the variational quantum algorithms for applications in quantum chemistry," The Journal of Chemical Physics, vol. 159, no. 4, p. 044117, 07 2023. [Online]. Available: https://doi.org/10.1063/5.0161057
[62] M. Fernández-Pendás, E. F. Combarro, S. Vallecorsa, J. Ranilla, and I. F. Rúa, "A study of the performance of classical minimizers in the quantum approximate optimization algorithm," Journal of Computational and Applied Mathematics, vol. 404, p. 113388, 2022. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0377042721000078
[63] F. Glover, G. Kochenberger, R. Hennig, and Y. Du, "Quantum bridge analytics i: A tutorial on formulating and using qubo models," Annals of Operations Research, vol. 314, no. 1, pp. 141-183, 072022. [Online]. Available: https://doi.org/10.1007/s10479-022-04634-2
[64] A. Lucas, "Ising formulations of many np problems," Frontiers in Physics, vol. 2, 2014. [Online]. Available: https://www.frontiersin.org/ articles/10.3389/fphy.2014.00005
[65] E. Pelofske, G. Hahn, and H. Djidjev, "Solving large maximum clique problems on a quantum annealer," in Quantum Technology and Optimization Problems, S. Feld and C. Linnhoff-Popien, Eds. Cham: Springer International Publishing, 2019, pp. 123-135.
[66] D. C. McKay, C. J. Wood, S. Sheldon, J. M. Chow, and J. M. Gambetta, "Efficient z-gates for quantum computing," Physical Review A, vol. 96, no. 2, Aug. 2017. [Online]. Available: http: //dx.doi.org/10.1103/PhysRevA.96.022330