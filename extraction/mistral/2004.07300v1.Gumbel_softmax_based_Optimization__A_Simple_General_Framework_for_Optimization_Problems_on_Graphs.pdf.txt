# Gumbel-softmax-based Optimization: A Simple General Framework for Optimization Problems on Graphs 

Yaoxin $\mathrm{Li}^{1}$, Jing $\mathrm{Liu}^{1}$, Guozheng $\mathrm{Lin}^{1}$, Yueyuan $\mathrm{Hou}^{2}$, Muyun $\mathrm{Mou}^{1}$ and Jiang Zhang ${ }^{1 *}$<br>*Correspondence:<br>zhangjiang@bnu.edu.cn<br>${ }^{1}$ School of Systems Science, Beijing Normal University, No. 19, Xinjiekousvai St, Haidian District, 100875 Beijing, P.R.China Full list of author information is available at the end of the article ${ }^{1}$ Equal contributor


#### Abstract

In computer science, there exist a large number of optimization problems defined on graphs, that is to find a best node state configuration or a network structure such that the designed objective function is optimized under some constraints. However, these problems are notorious for their hardness to solve because most of them are NP-hard or NP-complete. Although traditional general methods such as simulated annealing (SA), genetic algorithms (GA) and so forth have been devised to these hard problems, their accuracy and time consumption are not satisfying in practice. In this work, we proposed a simple, fast, and general algorithm framework based on advanced automatic differentiation technique empowered by deep learning frameworks. By introducing Gumbel-softmax technique, we can optimize the objective function directly by gradient descent algorithm regardless of the discrete nature of variables. We also introduce evolution strategy to parallel version of our algorithm. We test our algorithm on three representative optimization problems on graph including modularity optimization from network science, Sherrington-Kirkpatrick (SK) model from statistical physics, maximum independent set (MIS) and minimum vertex cover (MVC) problem from combinatorial optimization on graph. High-quality solutions can be obtained with much less time consuming compared to traditional approaches.


Keywords: Optimization problems on graphs; Gumbel-softmax; Evolution strategy

## Introduction

In computer science, there exist a large number of optimization problems defined on graphs, e.g., maximal independent set (MIS) and minimum vertex cover (MVC) problems [1]. In these problems, one is asked to give a largest (or smallest) subset of the graph under some constraints. In statistical physics, finding the ground state configuration of spin glasses model where the energy is minimized is another type of optimization problems on specific graphs [2]. Obviously, in the field of network science there are a great number of optimization problems defined on graphs abstracted from real-world networks. For example, modularity maximization problem [3] asks to specify which community one node belongs to so that the modularity value is maximized. In general, the space of possible solutions of mentioned problems is typically very large and grows exponentially with system size, thus impossible to solve by exhaustion.There are many algorithms for optimization problem. Coordinate descent algorithms (CD) which based on line search is a classic algorithm and solve optimization problems by performing approximate minimization along coordinate directions or coordinate hyperplanes [4]. However, it does not take gradient information into optimizing process and can be unstable on unsmooth functions. Particle swarm optimization (PSO) is another biologically derived algorithm that can be effective for optimizing a wide range of functions [5]. It is highly dependent on stochastic processes, and it does not take advantage of gradient information either. Other widely-used methods such as simulated annealing (SA) [6], genetic algorithm (GA) [7], extremal optimization (EO) [8] are capable of solving various kinds of problems. However, when it comes to combinatorial optimization problems on graphs, these methods usually suffer from slow convergence and are limited to system size up to thousand. Although there exist many other heuristic solvers such as local search [9], they are usually domain-specific and require special domain knowledge.

Fortunately, there are other optimization methods based on gradient descent that are able to work without suffering from these drawbacks. However, these gradient-based methods require the gradient calculation has to be designed manually throughout the optimization process for each specific problems, thereafter, they lack flexibility and generalizability.

Nowadays, with automatic differentiation technique [10] developed in deep learning area, gradient descent based methods have been renewed. Based on computational graph and tensor operation, this technique automatically calculates the derivative so that back propagation can work more easily. Once the forward computational process is well defined, the automatic differentiation framework can automatically compute the gradients of all variables with respect to the objective function.

Nevertheless, there exist combinatorial optimization problems on graphs whose objective functions are non-differentiable, therefore cannot be solved by using automatic differentiation technique. Some other techniques developed in reinforcement learning area seek to solve the problems directly without training and testing stages. For example, REINFORCE algorithm [11] is a typical gradient estimator for discrete optimization. Recently, reparameterization trick, which is a competitive candidate of REINFORCE algorithm for estimating gradient, is developed in machine learning community. For example, Gumbel-softmax [12, 13] provides another approach for differentiable sampling. It allows us to pass gradients through sampling process directly. It has been applied on various machine learning problems[12, 13].

With reparameterization trick such as Gumbel-softmax, it is possible to treat many discrete optimization problems on graphs as continuous optimization problems [14] and apply a series of gradient descent based algorithms [15]. Although these reinforcement learning and reparameterization tricks provide us a new way to solve discrete problems, when it comes to complicated combinatorial optimization problems on large graphs, the performances of these methods are not satisfying because they often stuck with local optimum.

Nowadays, a great number of hybrid algorithms taking advantage of both gradient descent and evolution strategy have shown their effectiveness over optimization problems $[16,17]$ such as function optimization. Other population based algorithms[18] also show potential to work together with gradient based methods to achieve better performance.

In this work, we present a novel general optimization framework based on automatic differentiation technique and Gumbel-softmax, including Gumbel-softmax optimization (GSO) [19] and Evolutionary Gumbel-softmax optimization (EvoGSO). The original Gumbel-softmax optimization algorithm applies Gumbel-softmax reparameterization trick on combinatorial problems on graphs directly to convert the original discrete problem into a continuous optimization problem such that the gradient decent method can be used. The batched version of GSO algorithm improves the results by searching the best solution in a group of optimization variables undergoing gradient decent optimization process in a parallel manner. The evolutionary Gumbel-softmax optimization method builds a mixed algorithm that combines the batched version of GSO algorithm and evolutionary computation methods. The key idea is to treat the batched optimization variables - the parameters as a population such that the evolutionary operators, e.g. substitution, mutation, and crossover can be applied. The introduction of evolutionary operators can significantly accelerate the optimization process.

We first introduce our method proposed in [19] and then the improved algorithm: Evolutionary Gumbel-softmax (EvoGSO). Then we give a brief description of three different optimization problems on graphs and specify our experiment configuration, followed by main results on these problems, compared with different benchmark algorithms. The results show that our framework can achieve competitive optimal solutions and also benefit from time consumption. Finally we give some concluding remarks and prospect of future work.

# The proposed algorithm 

In [19] we proposed Gumbel-softmax optimization (GSO), a novel general method for solving combinatorial optimization problems on graphs. Here we briefly introduce the basic idea of GSO and then introduce our improvement: Evolutionary Gumbel-softmax optimization (EvoGSO).

## Gumbel-softmax optimization (GSO)

Considering an optimization problems on graph with $N$ nodes, each node can take $K$ different values, i.e., selected or non-selected for $K=2$. Our goal is to find configuration $\mathbf{s}=\left(s_{1}, s_{2}, \cdots, s_{N}\right)$ that minimizes the objective function. Suppose we can sample from all allowed solution space easily, we want those configurations with lower objective function to have higher probabilities $p(\mathbf{s})$. Here, $p(\mathbf{s})$ is the joint distribution of solutions, which is the key for the optimization. There are a large number of methods to specify the joint distribution, among which the mean field factorization is the simplest one. That is, we factorize the joint distribution of solutions into the product of $N$ independent categorical distributions [20], which is also called naive mean-field in physics:

$$
p\left(s_{1}, s_{2}, \cdots, s_{N}\right)=\prod_{i=1}^{N} p_{\theta}\left(s_{i}\right)
$$and the marginal probability $p\left(s_{i}\right) \in[0,1]^{K}$ can be parameterized by a set of parameters $\theta_{i}$ which is easily generated by Sigmoid or softmax function.
It is easy to sample a possible solution $\mathbf{s}$ according to Equation 1 and then evaluate the objective function $E(\mathbf{s} ; \boldsymbol{\theta})$. However, due to the non-differentiable nature of sampling, we cannot estimate the gradients of $\boldsymbol{\theta}$ unless we resort to Monte Carlo gradient estimation techniques such as REINFORCE [11]. Gumbel-softmax [12], also known as concrete distribution [13] provides an alternative approach to tackle the difficulty of non-differentiability. Consider a categorical variable $s_{i}$ that can take discrete values $s_{i} \in\{1,2, \cdots, K\}$. This variable $s_{i}$ can be parameterized as a $K$-dimensional vector $\left(p_{1}, p_{2}, \cdots, p_{K}\right)$ where $\theta_{i}$ is the probability that $\theta_{i}=p\left(s_{i}=\right.$ $r), r=1,2, \cdots, K$. Instead of sampling a hard one-hot vector, Gumbel-softmax technique gives a $K$-dimensional sampled vector where the $i$-th entry is

$$
\hat{p}_{i}=\frac{\exp \left(\left(\log \left(p_{i}\right)+g_{i}\right) / \tau\right)}{\sum_{j=1}^{K} \exp \left(\left(\log \left(p_{j}\right)+g_{j}\right) / \tau\right)} \quad \text { for } i=1,2, \cdots, K
$$

where $g_{i} \sim \operatorname{Gumbel}(0,1)$ is a random variable following standard Gumbel distribution and $\tau$ is the temperature parameter. Notice that as $\tau \rightarrow 0$, the softmax function will approximate argmax function and the sampled vector will approach a one-hot vector. And the one-hot vector can be regarded as a sampled solution according to the distribution $\left(p_{1}, p_{2}, \cdots, p_{K}\right)$ because the unitary element will appear on the $i^{\text {th }}$ element in the one-hot vector with probability $p_{i}$, therefore, the computation of Gumbel-softmax function can simulate the sampling process. Furthermore, this technique allows us to pass gradients directly through the "sampling" process because all the operations in Equation 2 are differentiable. In practice, it is common to adopt a annealing schedule from a high temperature $\tau$ to a small temperature.
In a concise manner, we randomly initialize a series of learnable parameters $\boldsymbol{\theta}$ which are the variables for optimization and the probabilities $\boldsymbol{p}$ are generated by Sigmoid function over these parameters. Then we sample from $\boldsymbol{p}$ with Gumbelsoftmax technique to get solutions and calculate objective function. Finally, we run back propagation algorithm to update parameters $\boldsymbol{\theta}$. The whole process is briefly demonstrated in Figure 1.


Figure 1: Process of Gumbel-softmax optimization

# Parallel version of GSO 

We point out that our method can be implemented in parallel on GPU: $N_{\mathrm{bs}}$ different learnable parameters $\boldsymbol{\theta}$ can form a group which is called a batch. These parameters are initialized and optimized simultaneously. So we have $N_{\mathrm{bs}}$ candidate solutionsin a batch instead of one. When the optimizing procedure is finished, we select the solution with the best performance from this batch. In such a way, we can take full advantage of GPU acceleration and obtain better results more likely.
The whole process of optimization solution is presented in Algorithm (1).

```
Algorithm 1: Gumbel-softmax Optimization (GSO)
    Input: Problem size \(N\), batch size \(N_{\text {bs }}\), learning rate \(\eta\), and Graph \(\mathcal{G}\) for optimization.
    Output: solution with the best performance
    Initialize \(\boldsymbol{\theta}=\left(\theta_{1}, \theta_{2}, \cdots, \theta_{N}\right) \in \mathbb{R}^{N_{b s} \times N \times E}\);
    repeat
        \(\mathbf{s} \leftarrow\) Gumbel-softmax sampling from \(p_{\boldsymbol{\theta}}\left(p_{\boldsymbol{\theta}}=\operatorname{Sigmoid}(\boldsymbol{\theta})\right)\);
        \(E \leftarrow E(\mathbf{s} ; \boldsymbol{\theta})\);
        Backpropagation;
        \(\boldsymbol{\theta} \leftarrow \boldsymbol{\theta}-\eta \frac{\partial E}{\partial \boldsymbol{\theta}}\);
    until Convergence;
    Select solution with the best performance;
```


# Evolutionary Gumbel-softmax Optimization (EvoGSO) 

In parallelized GSO, simply selecting the result with the best performance from the batch can not take fully advantage of other candidates. Therefore, we propose an improved version of algorithm called Evolutionary Gumbel-softmax Optimization (EvoGSO) by combining evolutionary operators and Gumbel-softmax optimization method. The key idea is to treat a batch as a population so that we can perform population based evolution strategies [18] to improve this algorithm.
Evolution strategy and evolution programming [21] have shown their capability of solving many optimization problems, they bring diversity to the population and can potentially overcome the difficulty of local minima. In this work, we introduce two types of simple but effective operations to our original GSO algorithm: selective substitution inspired by swarm intelligence and evolutionary operators from genetic algorithm including selection, crossover and mutation.

## Selective substitution

During the process of gradient descent, we replace the parameters of worst $1 / u$ individuals with a series of alternative parameters every $T_{1}$ steps. Where, the ratio of substitution $1 / u$ and the evolution cycle $T_{1}$ are hyper-parameters which are varying according to specific problems. The alternative parameters can be the parameters with the best performance in the population, or the best ones with stochastic disturbance, or the ones randomly re-initialized in the problem domain [21]. This operation is particularly effective on population with high deviation and problems with severe local minima.

## Selection, crossover and mutation

When GSO reaches convergence where further optimized solutions cannot be found, we introduce these operators from the classic genetic algorithm to the population for the purpose of diversity and preservation of excellent genes (certain bits or segments of parameters). Here we adopt roulette wheel selection, single-point crossover and binary mutation as well as elitist preservation strategy [7]. Since this operation significantly change the structure of parameters which works against gradientdescent, the good performance can be achieved if the evolution operators are implemented after each convergence and with cycle $T_{2}$ long enough for the population to converge.
We present our proposed method in Algorithm (2).

```
Algorithm 2: EvoGSO
    Input: Problem size \(N\), batch size \(N_{\text {bs }}\), learning rate \(\eta\), and Graph \(\mathcal{G}\) for optimization. Evolution
        cycle \(T\), substitution ratio \(1 / u\), mutation rate \(m\).
    Output: solution with the best performance
    Initialize \(\boldsymbol{\theta}=\left(\theta_{1}, \theta_{2}, \cdots, \theta_{N}\right) \in \mathbb{R}^{N_{b s} \times N \times K}\);
    repeat
        \(\mathbf{s} \leftarrow\) Gumbel-softmax sampling from \(p_{\boldsymbol{\theta}}\left(p_{\boldsymbol{\theta}}=\operatorname{Sigmoid}(\boldsymbol{\theta})\right)\);
        \(E \leftarrow E(\mathbf{s} ; \boldsymbol{\theta})\);
        Backpropagation;
        \(\boldsymbol{\theta} \leftarrow \boldsymbol{\theta}-\eta \frac{\partial E}{\partial \boldsymbol{\theta}}\);
        do
            select best \(1 / u\) solutions and worst \(1 / u\) solutions;
            replace the parameters of the worst solutions by the parameters of the best solutions;
        while Every \(T_{1}\) steps and the variance of populations is larger than the threshold;
        do
            retain elite individuals;
            perform crossover and mutation operation and replace parents;
        while Every \(T_{2}\) steps after the first convergence of the gradient based steps;
    until Convergence;
    Select solution with the best performance;
```


# Experiments 

## A Simple Example

To show the importance and the efficiency of combining evolutionary operators and gradient based optimization method, we use a functional optimization problem as an example at first. We test the hybrid algorithm of evolutionary method and gradient based method on functional optimization problem for Griewank and Rastrigin functions (Figure 2). These functions are classic test functions for optimization algorithms since they contain lots of local minima, and the global minimum can be hard to find.
We run three different optimization algorithms on these functions: gradient descent(GD) with learning rate $\eta=0.01$, GD with random initialization with cycle $T=1000$ and hybrid algorithm of GD and evolution strategy with population size $N_{\mathrm{bs}}=64$, evolution cycle $T=1000$ and the substitution ratio $1 / u=1 / 4$ (see Figure 3 (a)). In gradient descent algorithm, candidates usually stuck in local minima after convergence (see Figure 3 (b)). After we add random initialization operation, candidates are able to jump out of these local minima and have more chance to find global minimum(see Figure 3 (c) and (d)). However, it is stochastic and candidates are unable to share information with each other. Finally we test a hybrid algorithm of GD and evolution strategy. We adopt selective substitution operation inspired by swarm intelligence, in which candidates are able to communicate so that the good results can be preserved and inherited(see Figure 3 (e)). Figure 3 illustrate five key frames on contour of Griewank function during the optimizing process of this hybrid algorithm and a comparison bar graph shows the number of global minimum found by different optimization algorithms in 100 instances. We can clearly see that the hybrid algorithm outperforms its two competitors and obtain global minimum more likely.

Figure 2: Images of two test functions


Figure 3: (a) to (e) are five key frames that illustrate how four candidate individuals with different colors converge to the global minimum at $(0,0)$ under the hybrid algorithm on the contour of Griewank function. (a) The initial positions of the four candidates. (b) The positions of the four candidates after the first convergence of gradient decent but without evolutionary operation. (c) The positions of the four candidates after the first evolutionary operation. (d) The positions of the four candidates after the second evolutionary operation. (e) The final positions of the four candidates. The bar graph in (f) shows the number of global minimums found by GD, GD with random initialization, and GD with selective substitution algorithms in 100 instances, respectively.# Combinatorial Optimization Problems on Graphs 

To further test the performance of our proposed algorithms, we conduct experiments on different optimization problems on graphs. We perform all experiments on a server with an Intel Xeon Gold 5218 CPU and NVIDIA GeForce RTX 2080Ti GPUs. For comparison, we mainly test the three general optimization algorithms: extremal optimization (EO) [8], simulated annealing (SA) [6] and genetic algorithm (GA).

## Modularity maximization

Modularity is a graph clustering index for detecting community structure in complex networks [22]. Suppose a graph $\mathcal{G}(\mathcal{V}, \mathcal{E})$ is partitioned into $K$ communities, the objective is to maximize the following modularity function such that the best partition for nodes can be found,

$$
E\left(s_{1}, s_{2}, \cdots, s_{N}\right)=\frac{1}{2|\mathcal{E}|} \sum_{i j}\left[A_{i j}-\frac{k_{i} k_{j}}{2|\mathcal{E}|}\right] \delta\left(s_{i}, s_{j}\right)
$$

where $|\mathcal{E}|$ is the number of edges, $k_{i}$ is the degree of node $i, s_{i} \in\{0,1, \cdots, K-1\}$ is a label denoting which community of node $i$ belongs to, $\delta\left(s_{i}, s_{j}\right)=1$ if $s_{i}=s_{j}$ and 0 otherwise. $A_{i j}$ is the adjacent matrix of the graph. Maximizing modularity in general graphs is an NP-hard problem [23].
We use the real-world datasets that have been well studied in [24, 3, 25]: Karate, Jazz, C.elegans and E-mail to test the algorithms. We run experiments on each dataset with the number of communities Ncoms ranging from 2 to 20 . We run 10 instances for each fixed Ncoms. After the optimization process for the modularity in all Ncoms values, we report the maximum modularity value $Q$ and the corresponding Ncoms in Table 1. Our proposed methods have achieved competitive modularity values on all datasets compared to hierarchical agglomeration [24] and EO [25].

Table 1: Results on modularity optimization. ${ }^{1,2}$

| Graph | Size | $[24]$ | EO [25] | GSO $^{3}$ | EvoGSO $^{4}$ |
| :--: | :--: | :--: | :--: | :--: | :--: |
| Karate | 34 | $0.3810 / 2$ | $0.4188^{*} / 4$ | $\mathbf{0 . 4 1 9 8} / 4$ | $\mathbf{0 . 4 1 9 8} / 4$ |
| Jazz | 198 | $0.4379 / 4$ | $\mathbf{0 . 4 4 5 2} / 5$ | $0.4451^{*} / 4$ | $0.4451^{*} / 4$ |
| C.elegans | 453 | $0.4001 / 10$ | $0.4342^{*} / 12$ | $0.4304 / 8$ | $\mathbf{0 . 4 4 1 8} / 11$ |
| E-mail | 1133 | $0.4796 / 13$ | $\mathbf{0 . 5 7 3 8} / 15$ | $0.5275 / 8$ | $0.5655^{*} / 15$ |

[^0]Figure 4 further shows the modularity value with different number of communities on C.elegans and E-mail. Comparing to GA and SA, our proposed methods have achieved much higher modularity for different number of communities.


[^0]:    ${ }^{1}$ We report the maximum modularity value $Q$ and the corresponding number of communities Ncoms in the form of $(Q / N$ coms $)$.
    ${ }^{2}$ The best and the second best results are denoted in bold and asterisk respectively.
    ${ }^{3}$ Configuration: batch size $=256$, initial $\tau=0.5$, final $\tau=0.1$, learning rate $=0.01$, instance $=10$.
    ${ }^{4}$ Configuration: batch size $=256$, initial $\tau=0.5$, final $\tau=0.1$, learning rate $=0.01$, instance $=10$, cycle $T_{1}=100$, cycle $T_{2}=5000$, substitution ratio $1 / u=1 / 8$, mutation rate $m=0.001$, elite ratio $=0.0625$.

Figure 4: Results on modularity optimization. In experiments, we suppose that the graph is partitioned into $K$ communities with $K$ ranging from 2 to 10 and report the maximum modularity value Q. We only perform experiments on two larger graphs: C.elegans and E-mail since the sizes of karate and Jazz are too small. Experiment configuration: (GSO/EvoGSO) : batch size $=256$, initial $\tau$ $=0.5$, final $\tau=0.1$, learning rate $=0.01$, instance $=10$, cycle $T_{1}=100$, cycle $T_{2}=5000$, substitution ratio $1 / u=1 / 8$, mutation rate $m=0.001$, elite ratio $=0.0625$. (GA) : population size $=64$, crossover rate $=0.8$, mutation rate $=$ 0.001 , elite ratio $=0.125$.# Sherrington-Kirkpatrick (SK) model 

SK model is a celebrated spin glasses model defined on a complete graph [26]. Each node represents an Ising spin $\sigma_{i} \in\{-1,+1\}$ and the interaction between spins $\sigma_{i}$ and $\sigma_{j}$ is $J_{i j}$ sampled from a Gaussian distribution $\mathcal{N}(0,1 / N)$ where $N$ is the number of spins. We are asked to give an assignment of each spin so that the objective function, or the ground state energy

$$
E\left(\sigma_{1}, \sigma_{2}, \cdots, \sigma_{N}\right)=-\sum_{1 \leq i<j \leq N} J_{i j} \sigma_{i} \sigma_{j}
$$

is minimized. It is also an NP-hard problem [2].
We test our algorithms on SK model with various sizes ranging from 256 to 8192. The state-of-the-art results are obtained by EO [8]. The results are shown in Table 2 and Table 3. From Table 2 we see that although EO has obtained lower ground state energy, it only reported results of system size up to $N=1024$ because it is extremely time-consuming. In fact, the algorithmic cost of EO is $\mathcal{O}\left(N^{4}\right)$. In the implementation of SA and GA, we set the time limit to be 96 hours and the program failed to finish for some $N$ in both algorithms. Although the results of SA are much better than GA, they are still not satisfying for larger $N$. For SK model, we adopt only selective substitution in EvoGSO.

Table 2: The results on optimization of ground state energy of SK model compared to Extremal optimization (EO), genetic algorithm (GA) and simulated annealing (SA). ${ }^{1}$

| N | I | EO [27] | GA $^{2}$ | SA | GSO $\left(N_{b s}=1\right)^{3}$ |
| :--: | :--: | :--: | :--: | :--: | :--: |
| 256 | 5000 | $-\mathbf{0 . 7 4 5 8 5 ( 2 )} / \sim 268 \mathrm{~s}$ | $-0.6800(3) / 16.3 \mathrm{~s}$ | $-0.7278(2) / 1.28 \mathrm{~s}$ | $-0.7267(2) / 0.99 \mathrm{~s}$ |
| 512 | 2500 | $-\mathbf{0 . 7 5 2 3 5 ( 3 )} / \sim 1.2 \mathrm{~h}$ | $-0.6580(3) / 60.06 \mathrm{~s}$ | $-0.7327(2) / 3.20 \mathrm{~s}$ | $-0.7405(2) / 2.16 \mathrm{~s}$ |
| 1024 | 1250 | $\mathbf{0 . 7 5 6 3 ( 2 )} / \sim 20 \mathrm{~h}$ | $-0.6884(4) / 236.21 \mathrm{~s}$ | $-0.7352(2) / 15.27 \mathrm{~s}$ | $-0.7480(2) / 4.49 \mathrm{~s}$ |
| 2048 | 400 | - | - | $-0.7367(2) / 63.27 \mathrm{~s}$ | $-\mathbf{0 . 7 5 2 4 ( 2 )} / 7.23 \mathrm{~s}$ |
| 4096 | 200 | - | - | $-0.73713(6) / 1591.93 \mathrm{~s}$ | $-\mathbf{0 . 7 5 5 1 ( 2 )} / 10.46 \mathrm{~s}$ |
| 8192 | 100 | - | - | - | $-\mathbf{0 . 7 5 6 2 ( 1 )} / 25.15 \mathrm{~s}$ |

${ }^{1}$ The best results are denoted in bold. Corresponding standard error of the mean is given in brackets.
${ }^{2}$ Configuration: population size $=64$, crossover rate $=0.8$, mutation rate $=0.001$, elite ratio $=0.125$.
${ }^{3}$ Configuration: initial $r=20$, final $r=1$, learning rate $=1$.
We also compare Gumbel-softmax based algorithms with different batch sizes and the EvoGSO. From Table 3 we see that with the implementation of the parallel version, the results can be improved greatly. Besides, the EvoGSO outperforms GSO for larger $N$.

Maximal Independent Set (MIS) and Minimum Vertex Cover (MVC) problems MIS and MVC problems are canonical NP-hard combinatorial optimization problems on graphs [1]. Given an undirected graph $\mathcal{G}(\mathcal{V}, \mathcal{E})$, the MIS problem asks to find the largest subset $\mathcal{V}^{\prime} \subseteq \mathcal{V}$ such that no two nodes in $\mathcal{V}^{\prime}$ are connected by an edge in $\mathcal{E}$. Similarly, the MVC problem asks to find the smallest subset $\mathcal{V}^{\prime} \subseteq \mathcal{V}$ such that every edge in $\mathcal{E}$ is incident to a node in $\mathcal{V}^{\prime}$. MIS and MVC are constrained optimization problems and cannot be optimized directly by our framework. Here we adopt penalty method and Ising formulation to transform them into unconstrained problems.Table 3: The results on optimization of ground state energy of SK model. We show that the parallel version of our proposed methods and EvoGSO can greatly improve the performance. ${ }^{1}$

| N | I | GSO $\left(N_{b s}=1\right)^{2}$ | GSO $\left(N_{b s}=128\right)^{2}$ | EvoGSO $\left(N_{b s}=128\right)^{3}$ |
| :--: | :--: | :--: | :--: | :--: |
| 256 | 5000 | $-0.7267(2) / 0.99 \mathrm{~s}$ | $-\mathbf{0 . 7 3 6 9 ( 1 )} / 0.96 \mathrm{~s}$ | $-0.7364(1) / 0.89 \mathrm{~s}$ |
| 512 | 2500 | $-0.7405(2) / 2.16 \mathrm{~s}$ | $-\mathbf{0 . 7 4 6 4 ( 1 )} / 2.14 \mathrm{~s}$ | $-0.7462(1) / 2.01 \mathrm{~s}$ |
| 1024 | 1250 | $-0.7480(2) / 4.49 \mathrm{~s}$ | $-\mathbf{0 . 7 5 2 1 ( 1 )} / 4.66 \mathrm{~s}$ | $-0.7516(4) / 4.41 \mathrm{~s}$ |
| 2048 | 400 | $-0.7524(2) / 7.23 \mathrm{~s}$ | $-0.7555(2) / 8.07 \mathrm{~s}$ | $-\mathbf{0 . 7 5 5 7 ( 1 )} / 7.51 \mathrm{~s}$ |
| 4096 | 200 | $-0.7551(2) / 10.46 \mathrm{~s}$ | $-0.7566(5) / 12.78 \mathrm{~s}$ | $-\mathbf{0 . 7 5 6 9 ( 3 )} / 12.80 \mathrm{~s}$ |
| 8192 | 100 | $-0.7562(1) / 25.15 \mathrm{~s}$ | $-0.7568(8) / 49.13 \mathrm{~s}$ | $-\mathbf{0 . 7 5 7 8 ( 5 )} / 49.04 \mathrm{~s}$ |

${ }^{1}$ The best results are denoted in bold. The corresponding standard error of the mean is given in brackets.
${ }^{2}$ Configuration: initial $\tau=20$, final $\tau=1$, learning rate $=1$.
${ }^{3}$ Configuration: initial $\tau=20$, final $\tau=1$, learning rate $=1$, cycle $T_{1}=100$, substitution ratio $1 / u=1 / 8$.

We can place an Ising spin $\sigma_{i}$ on each node and then define the binary bit variable $x_{i}=\left(\sigma_{i}+1\right) / 2$. Here $x_{i}=1$ means that node $i$ belongs to the subset $\mathcal{V}^{\prime}$ and $x_{i}=0$ otherwise. Thus the Ising Hamiltonians for MIS problem is

$$
E\left(x_{1}, x_{2}, \cdots, x_{N}\right)=-\sum_{i} x_{i}+\alpha \sum_{i j \in \mathcal{E}} x_{i} x_{j}
$$

Similarly, the Ising Hamiltonians for MVC becomes

$$
E\left(x_{1}, x_{2}, \cdots, x_{N}\right)=\sum_{i} x_{i}+\alpha \sum_{i j \in \mathcal{E}}\left(1-x_{i}\right)\left(1-x_{j}\right)
$$

where $\alpha>0$. The first term on right hand side is the number of selected nodes and the second term provides a penalty if selected nodes violate constraint. $\alpha$ is a penalty parameter and its value is crucial to the performance of our framework. If $\alpha$ is set too small, we may not find any feasible solutions. Conversely, if it is set too big, we may find lots of feasible solutions whose qualities are not satisfying. In this work, we set $\alpha$ to 3 , which assures both quality and amount of feasible solutions.
We test our algorithms on three citation graphs: Cora, Citeseer and PubMed. Beyond the standard general algorithms like Genetic Algorithm and Simulating Anealing, we also compare with other deep learning based algorithms including (1) Structure2Vec Deep Q-learning (S2V-DQN) [28]: a reinforcement learning method to address optimization problems over graphs, and (2) Graph Convolutional Networks with Guided Tree Search (GCNGTS) [29]: a supervised learning method based on graph convolutional networks (GCN) [30], as well as the well known greedy algorithms on MIS and MVC problems like (3) greedy algorithm (Greedy) and Minimum-degree greedy algorithm (MD-Greedy) [31]: a simple and well-studied method for finding independent sets in graphs.
We run 20 instances and report results with best performance. The results of MIS and MVC problems are shown in Table 4. Our proposed algorithms have obtained much better results compared to the classical general optimization methods including greedy and SA on all three datasets. Although our methods cannot beat MD-Greedy algorithm, they do not use any prior information about the graph.However, MD-Greedy requires to compute degrees of all nodes on the graph. Further, we do not report the results of GA algorithm because without heuristic and specific design, the general GA failed to find any feasible solution since MIS and MVC are constrained optimization problems.

Table 4: Results on MIS and MVC problems compared to classic methods and supervised deep learning methods. ${ }^{1}$

|  | Graph Info |  | Classic |  | Supervised |  |  | Proposed |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  | Name | Size | MD-Greedy | Greedy | SA | S2V-DQN | GCNGTS | $\mathrm{GSO}^{2} /$ EvoGSO ${ }^{3}$ |
| MIS | Cora | 2708 | 1451 | 672 | 1390 | 1381 | 1451 | $1443^{*}$ |
|  | Citeseer | 3327 | $1818^{*}$ | 1019 | 1728 | 1705 | 1867 | 1795 |
|  | PubMed | 19717 | 15912 | 5353 | 14703 | 15709 | 15912 | $15886^{*}$ |
| MVC | Cora | 2708 | 1257 | 2036 | 1318 | 1327 | 1257 | $1265^{*}$ |
|  | Citeseer | 3327 | $1509^{*}$ | 2308 | 1599 | 1622 | 1460 | 1533 |
|  | PubMed | 19717 | 3805 | 14364 | 5014 | 4008 | 3805 | $3831^{*}$ |

${ }^{1}$ The best and the second best results are denoted in bold and asterisk respectively.
${ }^{2}$ Configuration: batch size $=128$, fixed $\tau=1$, learning rate $=0.01, \alpha=3$, instance $=20$.
${ }^{3}$ Configuration: batch size $=512$, fixed $\tau=1$, learning rate $=0.01, \alpha=3$, instance $=20$, cycle $T_{1}=$ 100, substitution ratio $1 / u=1 / 8$, cycle $T_{2}=10000$, mutation rate $m=0.001$, elite ratio $=0.0625$.

It is necessary to emphasize that the differences between our framework and other deep learning based algorithms such as S2V-DQN and GCNGTS. These algorithms belong to supervised learning, thus contain two stages of problem solving: training the solver at first, and then testing. Although relatively good solutions can be obtained efficiently, they must consume a great deal of time for training the solver and the quality of solutions depend heavily on the quality and the amount of the data for training. These features can hardly extend for large graphs. Comparatively, our proposed framework is more direct and light-weight, for it contains only optimization stage. It requires no training part and has no dependence on data or specific domain knowledge at all, therefore can easily be generalized and modified for different optimization problems.

# Sensitivity analysis on hyper-parameters 

We also perform experiments to test how hyper-parameters in evolution operation affects the performance of our algorithms. We have tried different population size $N_{b s}$, evolution cycle $T_{1}$ and substitution ratio $1 / u$ on SK model with 1024 and 8192 nodes. The default configurations are: initial $\tau=20$, final $\tau=1$, learning rate $\eta=1, N_{b s}=128, T_{1}=100,1 / u=1 / 8$, and then we change one hyperparameter every time for test. The results are shown in Figure 5. We can see that our framework shows different sensitivity to these hyper-parameters as they changes, and a relatively satisfying combination of hyper-parameters can be given from this research.

## Conclusion

In this work, we present a simple general framework for solving optimization problems on graphs. Our method is based on advanced automatic differentiation techniques and Gumbel-softmax technique which allows the gradients passing through sampling processes directly. We assume that all nodes in the network are independent and thus the joint distribution is factorized as a product distributions of each

Figure 5: Results on hyper-parameters tuning of population size *N*bs, evolution cycle *T* and substitution ratio 1/*u* on SK model with 1024 and 8192 nodes. Experiment configuration: initial τ = 20, final τ = 1, learning rate η = 1. The results are averaged for 1250 instances with 1024 nodes and 100 instances with 8192 nodes respectively.

node. This enables Gumbel-softmax sampling process efficiently. Furthermore, we introduce evolution strategy into our framework, which brings diversity and improves the performance of our algorithm. Our experiment results show that our method has good performance on all three tasks and also take advantages in time complexity. Comparing to the traditional general optimization methods such as GA and SA, our framework can tackle large graphs easily and efficiently. Though not competitive to state-of-the-art deep learning based method, our framework has the advantage of requiring neither training the solver nor specific domain knowledge. In general, it is an efficient, general and lightweight optimization framework for solving optimization problems on graphs.

However, there is much space to improve our algorithm on accuracy. In this paper, we take the mean field approximation as our basic assumption, however, the variables are not independent on most problems. Therefore, much more sophisticated variational distributions can be considered in the future. Another way to improve accuracy is to combine other skills such as local search in our framework. Since our framework is general and requires no specific domain knowledge, it shall be tested for solving other complex optimization problems in the future.

#### **Abbreviations**

GSO: Gumbel-softmax optimization; EvoGSO: Evolutionary Gumbel-softmax optimization.

#### **Acknowledgements**

This research is supported by the National Natural Science Foundation of China (N5FC) (no. 61673070) and the Fundamental Research Funds for the Central Universities (no. 2020KJZX004).

#### **Author's contributions**

J.Z., Y.L. and J.L. conceived and designed the research. Y.L., J.L. and J.Z. designed the model structure. Y.L. and J.L. developed the model. Y.L., J.L., G.L., Y.H. and M.M. performed the experiments. J.Z., Y.L. and J.L. wrote the manuscript. J.Z. reviewed and revised the manuscript. J.Z. supervised the research.

#### **Funding**

Not applicable.# Availability of data and materials 

The dataset analyzed in this study is publicly available online at http://networkrepository.com/.

## Competing interests

The authors declare that they have no competing interests.

## Author details

${ }^{1}$ School of Systems Science, Beijing Normal University, No.19, Xinjiekouwai St, Haidian District, 100875 Beijing, P.R.China. ${ }^{2}$ ColorfulClouds Tech, No.04, Building C, 768 Creative Industrial Park, Compound 5A, Xueyuan Road, Haidian District, 100083 Beijing, P.R.China.

## References

1. Karp, R.M.: Reducibility among combinatorial problems. In: Complexity of Computer Computations, pp. 85-103. Springer, ??? (1972)
2. Mézard, M., Parisi, G., Virasoro, M.: Spin Glass Theory and Beyond: An Introduction to the Replica Method and Its Applications vol. 9. World Scientific Publishing Company, ??? (1987)
3. Newman, M.E.: Modularity and community structure in networks. Proceedings of the national academy of sciences 103(23), 8577-8582 (2006)
4. Wright, S.J.: Coordinate descent algorithms. Mathematical Programming 151(1), 3-34 (2015). doi:10.1007/s10107-015-0892-3. 1502.04759
5. Kennedy, J., Eberhart, R.C.: Particle swarm optimization. In: Proceedings of the IEEE International Conference on Neural Networks, pp. 1942-1948 (1995)
6. Kirkpatrick, S., Gelatt, C.D., Vecchi, M.P.: Optimization by simulated annealing. science 220(4598), 671-680 (1983)
7. Davis, L.: Handbook of genetic algorithms (1991)
8. Boettcher, S., Percus, A.: Nature's way of optimizing. Artificial Intelligence 119(1-2), 275-286 (2000)
9. Andrade, D.V., Resende, M.G., Werneck, R.F.: Fast local search for the maximum independent set problem. Journal of Heuristics 18(4), 525-547 (2012)
10. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in pytorch. In: NIPS-W (2017)
11. Williams, R.J.: Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning 8(3-4), 229-256 (1992)
12. Jang, E., Gu, S., Poole, B.: Categorical reparameterization with gumbel-softmax. In: 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, ??? (2017). https://openreview.net/forum?id=rkE3y85ee
13. Maddison, C.J., Mnih, A., Teh, Y.W.: The concrete distribution: A continuous relaxation of discrete random variables. In: 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings (2017). https://openreview.net/forum?id=S1jESLSgI
14. Andreasson, N., Evgrafov, A., Patriksson, M.: An Introduction to Continuous Optimization: Foundations and Fundamental Algorithms, 400 (2007)
15. Avraamidou, S., Pistikopoulos, E.N.: Optimization of Complex Systems: Theory, Models, Algorithms and Applications vol. 991, pp. 579-588. Springer, ??? (2020). doi:10.1007/978-3-030-21803-4. http://link.springer.com/10.1007/978-3-030-21803-4
16. Zidani, H., Ellaia, R., de Cursi, E.S.: A Hybrid Simplex Search for Global Optimization with Representation Formula and Genetic Algorithm. In: Advances in Intelligent Systems and Computing, vol. 991, pp. 3-15. Springer, ??? (2020)
17. Rocha, A.M.A., Costa, M.F.P., Fernandes, E.M.: A population-based stochastic coordinate descent method. In: World Congress on Global Optimization, pp. 16-25 (2019). Springer
18. Yildiz, A.R.: A comparative study of population-based optimization algorithms for turning operations. Information Sciences 210, 81-88 (2012). doi:10.1016/j.ins.2012.03.005
19. Liu, J., Gao, F., Zhang, J.: Gumbel-softmax optimization: A simple general framework for combinatorial optimization problems on graphs. In: International Conference on Complex Networks and Their Applications, pp. 879-890 (2019). Springer
20. Wainwright, M.J., Jordan, M.I., et al.: Graphical models, exponential families, and variational inference. Foundations and Trends ${ }^{\circledR}$ in Machine Learning 1(1-2), 1-305 (2008)
21. Bäck, T., Bäck, T., Rudolph, G., Schwefel, H.-p.: Evolutionary Programming and Evolution Strategies: Similarities and Differences. IN PROCEEDINGS OF THE SECOND ANNUAL CONFERENCE ON EVOLUTIONARY PROGRAMMING, 11-22
22. Fortunato, S.: Community detection in graphs. Physics reports 486(3-5), 75-174 (2010)
23. Brandes, U., Delling, D., Gaertler, M., Görke, R., Hoefer, M., Nikoloski, Z., Wagner, D.: On finding graph clusterings with maximum modularity. In: International Workshop on Graph-Theoretic Concepts in Computer Science, pp. 121-132 (2007). Springer
24. Newman, M.E.: Fast algorithm for detecting community structure in networks. Physical review E 69(6), 066133 (2004)
25. Duch, J., Arenas, A.: Community detection in complex networks using extremal optimization. Physical review E 72(2), 027104 (2005)
26. Sherrington, D., Kirkpatrick, S.: Solvable model of a spin-glass. Physical review letters 35(26), 1792 (1975)
27. Boettcher, S.: Extremal optimization for sherrington-kirkpatrick spin glasses. The European Physical Journal B-Condensed Matter and Complex Systems 46(4), 501-505 (2005)
28. Khalil, E., Dai, H., Zhang, Y., Dilkina, B., Song, L.: Learning combinatorial optimization algorithms over graphs. In: Advances in Neural Information Processing Systems, pp. 6348-6358 (2017)29. Li, Z., Chen, Q., Koltun, V.: Combinatorial optimization with graph convolutional networks and guided tree search. In: Advances in Neural Information Processing Systems, pp. 539-548 (2018)
30. Kipf, T.N., Welling, M.: Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016)
31. Halldórsson, M.M., Radhakrishnan, J.: Greed is good: Approximating independent sets in sparse and bounded-degree graphs. Algorithmica 18(1), 145-163 (1997)