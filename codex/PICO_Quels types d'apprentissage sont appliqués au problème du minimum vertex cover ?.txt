==== MÉTA ====
TITRE COURT : Apprentissage pour Minimum Vertex Cover
QUESTION DE RECHERCHE : Quels types d'apprentissage sont appliqués au problème du minimum vertex cover ?
DOMAINE / PROBLÈME : Théorie des graphes; optimisation combinatoire; problème du minimum vertex cover (MVC) sur graphes non orientés.
TYPE DE QUESTION (théorique / expérimental / mixte) : mixte
RÉSUMÉ PICO (2–3 lignes) : Étudier, classifier et évaluer les approches d'apprentissage (GNN supervisés/auto-supervisés, apprentissage par renforcement, imitation/learning-augmented) visant à produire une couverture minimale de sommets ou à guider des solveurs pour MVC. Comparer ces approches aux heuristiques classiques et solveurs exacts sur des familles de graphes variées, en mesurant qualité de solution, garanties théoriques lorsque disponibles, et performances.

==== PICO ====
PROBLÈMES / INSTANCES (P) : Graphes simples non orientés, non pondérés par défaut; tailles petites à grandes (n de 50 à >10^5), densités variées; familles: aléatoires (Erdős–Rényi), échelles libres (Barabási–Albert), planaires/grilles, graphes réels (réseaux, circuits). Variantes pondérées et biparties considérées en analyse secondaire si nécessaire.
ALGORITHME / MÉTHODE (I) : Méthodes d'apprentissage pour MVC comprenant: réseaux de neurones de graphes (GNN) produisant des scores/étiquettes de sommets; apprentissage par renforcement sélectionnant itérativement des sommets; imitation/apprentissage augmenté par des solveurs (apprentissage de politiques ou d'ordonnancements); apprentissage auto/non supervisé avec pertes de couverture d'arêtes; intégrations « learning-augmented » dans des pipelines exacts/heuristiques.
COMPARATEUR (C) : Baselines classiques sans apprentissage: heuristique gloutonne 2-approx basée sur couplage maximal ou degré; recherche locale; kernelisation + heuristique; solveurs exacts (ILP/branch-and-cut) pour instances petites/moyennes; variantes spécialisées sur graphes bipartis.
MESURES / PROPRIÉTÉS (O) : Taille de couverture; écart relatif à l’optimum/borne inférieure; taux de faisabilité (toutes arêtes couvertes); ratio d’approximation observé et garanties lorsque disponibles; temps CPU/GPU et mémoire; scalabilité (n, m); robustesse/généralisation hors distribution; ablations de composantes.

==== DÉLIMITATION DE LA PORTÉE ====
- Reformulations proposées (2–3) :
  1) Évaluer expérimentalement GNN, RL et imitation learning pour approximer MVC sur graphes génériques.
  2) Étudier l’apport de politiques apprises comme heuristiques d’exploration dans des solveurs exacts pour MVC.
  3) Comparer apprentissage supervisé vs renforcement pour la sélection de sommets dans MVC, à budget temps fixé.
- Reformulation retenue : Évaluer expérimentalement GNN, RL et imitation/learning-augmented pour approximer MVC sur graphes variés, à budget temps/ressources contrôlé, avec comparaison à heuristiques/solveurs classiques.
- Inclusions / exclusions **méthodologiques** internes au PICO (périmètre technique uniquement) : Inclus: méthodes produisant explicitement une couverture ou guidant un solveur MVC; entraînement et inférence sur graphes simples non orientés; comparaison à baselines standards. Exclus: méthodes ne visant pas MVC (p.ex., uniquement MaxClique/MaxCut sans réduction explicite), hypergraphes, graphes dynamiques fortement temporels sauf indication, supervision par données synthétiques non traçables.

==== PROTOCOLE D’ÉVALUATION / BENCHMARK (SI EXPÉRIMENTAL) ====
- Données/familles de graphes, budgets, seeds, métriques rapportées, équité des comparaisons.
  - Familles: Erdős–Rényi G(n,p), Barabási–Albert, grilles/planaires, graphes réels (réseaux, circuits), bipartis pour analyses spécifiques.
  - Tailles: paliers (n ∈ {100, 1k, 10k, 100k}) sous contraintes mémoire/temps; densités variées.
  - Vérité terrain / bornes: optimum via ILP pour petites instances; bornes via couplage maximal; meilleures solutions connues pour grandes.
  - Budgets: temps d’entraînement total et par époque; temps d’inférence par graphe; limites CPU/GPU identiques pour toutes méthodes.
  - Seeds: ≥5 seeds; rapporter moyenne ± écart-type; splits train/val/test sans fuite d’instances.
  - Métriques: taille, gap (%) à optimum/borne, faisabilité, temps, mémoire, taux d’échec; courbes qualité-temps.
  - Équité: mêmes pré/post-traitements, mêmes limites de temps/mémoire, tuning identique; pas d’accès aux solutions cibles à l’inférence.

==== QUALITÉ & REPRODUCTIBILITÉ ====
- Code/disponibilité, versionnement, contrôle des aléas, transparence des baselines.
  - Publier code et versions; scripts de génération des graphes; checkpoints et instructions d’entraînement.
  - Contrôler aléas (seeds, déterminisme partiel); journaliser hardware et budgets.
  - Décrire précisément baselines (implémentations, paramètres, critères d’arrêt); fournir notebooks de reproduction; consigner échecs/cas limites.

==== HYPOTHÈSES & INCERTITUDES ====
- Hypothèses posées ; points ambigus ; limites attendues.
  - Hypothèses: objectif MVC non pondéré principal; accès à solveurs pour petites instances; données d’entraînement représentatives; limites de ressources réalistes.
  - Incertitudes: transfert hors distribution; sensibilité aux tailles très grandes; équilibre performance-temps; qualité des labels (si supervision).
  - Limites: garanties théoriques des modèles appris souvent absentes; résultats dépendants des distributions de graphes et de l’ingénierie.

==== CHECKLIST FINALE ====
- P/I/C/O cohérents et traçables ; protocole (si applicable) défini ; hypothèses explicites.

==== NOM DE FICHIER ====
PICO_Quels types d'apprentissage sont appliqués au problème du minimum vertex cover ?.txt
