==== MÉTA ====
TITRE COURT : Apprentissage pour Minimum Vertex Cover
QUESTION DE RECHERCHE : Quels types d'apprentissage sont appliqués au problème du minimum vertex cover ?
DOMAINE / PROBLÈME : Théorie des graphes ; problème du minimum vertex cover (MVC).
TYPE DE QUESTION (théorique / expérimental / mixte) : mixte
RÉSUMÉ PICO (2–3 lignes) : Étudier, formaliser et comparer des approches d’apprentissage pour construire une couverture de sommets dans des graphes. Évaluer des méthodes supervisées (GNN) et par renforcement qui génèrent une couverture, face à des algorithmes classiques (2-approx, glouton) et à des solveurs exacts sur petites instances, en mesurant qualité, garanties et coûts.

==== PICO ====
PROBLÈMES / INSTANCES (P) : Graphes simples, non orientés, non pondérés ; tailles petites à moyennes ; familles synthétiques (Erdős–Rényi, Barabási–Albert) et instances réelles statiques ; objectif : trouver une couverture de sommets minimale.
ALGORITHME / MÉTHODE (I) : Méthodes d’apprentissage pour construire/proposer une couverture : (i) modèles supervisés basés GNN scorant les sommets et générant un ensemble couvrant ; (ii) apprentissage par renforcement (policy/value) guidant des choix séquentiels d’inclusion de sommets ; (iii) imitation/learning-to-search initialisé par une heuristique de référence.
COMPARATEUR (C) : Algorithme 2-approx par couplage maximal ; heuristique gloutonne par degrés ; recherche locale ; ILP/Branch-and-Bound exact sur petites instances (oracle d’optimalité).
MESURES / PROPRIÉTÉS (O) : Taille de la couverture et écart à l’optimum ; ratio d’approximation observé ; temps CPU et mémoire ; stabilité (variance sur seeds) ; généralisation hors distribution ; garanties théoriques explicites ou inexistantes selon la méthode.

==== DÉLIMITATION DE LA PORTÉE ====
- Reformulations proposées (2–3) :
- 1) Quelles méthodes d’apprentissage supervisé ou par renforcement surpassent des heuristiques classiques pour MVC non pondéré sur graphes simples ?
- 2) Dans quelle mesure des GNN entraînés sur des familles de graphes synthétiques se généralisent-ils à des graphes réels pour MVC ?
- 3) Comment des politiques RL neuro-guidées se comparent-elles à l’algorithme 2-approx et aux solveurs ILP en termes de ratio/temps ?
- Reformulation retenue : Comparer des GNN supervisés et des politiques RL pour MVC non pondéré sur graphes simples, face à 2-approx, glouton et ILP, en mesurant ratio, temps et généralisation.
- Inclusions / exclusions méthodologiques internes au PICO (périmètre technique uniquement) : Inclus : graphes simples non orientés non pondérés ; méthodes GNN, RL, imitation ; baselines 2-approx, glouton, ILP (petites instances). Exclus : graphes orientés, temporels/dynamiques, hypergraphes ; variantes pondérées ou contraintes supplémentaires ; utilisation d’attributs de nœuds hors structure pure, sauf degré.

==== PROTOCOLE D’ÉVALUATION / BENCHMARK (SI EXPÉRIMENTAL) ====
- Données/familles de graphes : ER(n,p), BA(n,m), graphes planaires synthétiques ; sous-ensembles d’instances réelles statiques sans attributs.
- Budgets : limites d’epochs/temps identiques par méthode ; early stopping ; splits train/val/test par graphes ; pas de fuite de labels.
- Seeds : 5–10 seeds ; moyenne ± écart-type ; contrôle de l’ordre d’itération et du parallélisme.
- Métriques rapportées : taille absolue de la couverture ; ratio vs optimum (ILP) ou meilleure baseline ; temps CPU ; mémoire ; taux de faisabilité (ensemble couvrant).
- Équité des comparaisons : mêmes budgets et protocoles de tuning ; mêmes ressources matérielles ; implémentations de baselines vérifiées ; arrêt si dépassement des limites.

==== QUALITÉ & REPRODUCTIBILITÉ ====
- Code/disponibilité : dépôt public avec versionnement ; scripts d’entraînement/évaluation ; checkpoints et configs ; instructions d’environnement (venv/conda, versions CUDA si pertinent).
- Versionnement : verrouillage des dépendances ; hash des données générées ; journalisation des commits/expériences.
- Contrôle des aléas : fixation des seeds pour toutes bibliothèques ; tie-breaking déterministe ; nombre de threads fixé.
- Transparence des baselines : hyperparamètres publiés ; sources citées ; ré-implémentations alignées ; solveur ILP (version, options) documenté.

==== HYPOTHÈSES & INCERTITUDES ====
- Hypothèses posées : (i) graphes non pondérés ; (ii) attributs limités à la structure (degré, éventuellement centralités) ; (iii) solveur ILP disponible pour petites instances.
- Points ambigus : taille maximale « petite » pour ILP ; choix exact des familles réelles ; métriques secondaires (p. ex. mémoire peak) ; représentation d’entrée pour les méthodes d’apprentissage.
- Limites attendues : absence de garanties d’approximation pour certaines approches ML ; sensibilité au décalage de distribution ; scalabilité limitée des solveurs exacts ; coût d’entraînement des GNN/RL.

==== CHECKLIST FINALE ====
- P/I/C/O définis, cohérents et traçables.
- Protocole expérimental spécifié avec données, budgets, seeds, métriques, équité.
- Hypothèses explicites ; incertitudes et limites énoncées.
- Dernière ligne du fichier égale au nom du fichier.

==== NOM DE FICHIER ====
PICO_Quels_types_d_apprentissage_sont_appliques_au_probleme_du_minimum_vertex_cover.txt
